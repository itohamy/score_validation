WARNING:tensorflow:From /vilsrv-storage/dinari/miniconda3/envs/condirit/lib/python3.8/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

Num of model parameters 2212227 

I0506 12:06:47.028455 140299910223616 xla_bridge.py:260] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0506 12:06:47.029254 140299910223616 xla_bridge.py:260] Unable to initialize backend 'gpu': NOT_FOUND: Could not find registered platform with name: "cuda". Available platform names are: Host Interpreter
I0506 12:06:47.029877 140299910223616 xla_bridge.py:260] Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.
W0506 12:06:47.030094 140299910223616 xla_bridge.py:265] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0506 12:06:47.031844 140299910223616 dataset_info.py:361] Load dataset info from /home/tohamy/tensorflow_datasets/cifar10/3.0.2
W0506 12:06:47.035531 140299910223616 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.
W0506 12:06:47.035680 140299910223616 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.
I0506 12:06:47.035924 140299910223616 dataset_builder.py:282] Reusing dataset cifar10 (/home/tohamy/tensorflow_datasets/cifar10/3.0.2)
I0506 12:06:47.036100 140299910223616 dataset_builder.py:477] Constructing tf.data.Dataset for split train, from /home/tohamy/tensorflow_datasets/cifar10/3.0.2
W0506 12:06:48.714689 140299910223616 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.
W0506 12:06:48.714899 140299910223616 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.
I0506 12:06:48.715098 140299910223616 dataset_builder.py:282] Reusing dataset cifar10 (/home/tohamy/tensorflow_datasets/cifar10/3.0.2)
I0506 12:06:48.715235 140299910223616 dataset_builder.py:477] Constructing tf.data.Dataset for split test, from /home/tohamy/tensorflow_datasets/cifar10/3.0.2
I0506 12:06:48.865596 140299910223616 run_lib.py:132] Starting training loop at step 10001.
I0506 12:06:57.909604 140299910223616 run_lib.py:145] step: 10050, training_loss: 2.00669e+02
I0506 12:07:04.708432 140299910223616 run_lib.py:145] step: 10100, training_loss: 1.31966e+02
I0506 12:07:05.210314 140299910223616 run_lib.py:158] step: 10100, eval_loss: 1.01271e+02
I0506 12:07:11.513750 140299910223616 run_lib.py:145] step: 10150, training_loss: 7.34304e+01
I0506 12:07:17.729386 140299910223616 run_lib.py:145] step: 10200, training_loss: 1.11781e+02
I0506 12:07:17.780555 140299910223616 run_lib.py:158] step: 10200, eval_loss: 1.55482e+02
I0506 12:07:24.203371 140299910223616 run_lib.py:145] step: 10250, training_loss: 1.00122e+02
I0506 12:07:30.662282 140299910223616 run_lib.py:145] step: 10300, training_loss: 1.36337e+02
I0506 12:07:30.720769 140299910223616 run_lib.py:158] step: 10300, eval_loss: 1.54889e+02
I0506 12:07:36.867221 140299910223616 run_lib.py:145] step: 10350, training_loss: 1.71538e+02
I0506 12:07:43.157459 140299910223616 run_lib.py:145] step: 10400, training_loss: 1.43406e+02
I0506 12:07:43.208654 140299910223616 run_lib.py:158] step: 10400, eval_loss: 1.33421e+02
I0506 12:07:49.701944 140299910223616 run_lib.py:145] step: 10450, training_loss: 2.29575e+02
I0506 12:07:55.853308 140299910223616 run_lib.py:145] step: 10500, training_loss: 9.93637e+01
I0506 12:07:55.907306 140299910223616 run_lib.py:158] step: 10500, eval_loss: 1.99727e+02
I0506 12:08:02.153800 140299910223616 run_lib.py:145] step: 10550, training_loss: 1.79785e+02
I0506 12:08:08.443727 140299910223616 run_lib.py:145] step: 10600, training_loss: 2.01858e+02
I0506 12:08:08.497746 140299910223616 run_lib.py:158] step: 10600, eval_loss: 1.63007e+02
I0506 12:08:15.026137 140299910223616 run_lib.py:145] step: 10650, training_loss: 1.47557e+02
I0506 12:08:21.231330 140299910223616 run_lib.py:145] step: 10700, training_loss: 1.40493e+02
I0506 12:08:21.286856 140299910223616 run_lib.py:158] step: 10700, eval_loss: 1.71855e+02
I0506 12:08:27.437670 140299910223616 run_lib.py:145] step: 10750, training_loss: 1.81880e+02
I0506 12:08:33.739442 140299910223616 run_lib.py:145] step: 10800, training_loss: 1.16983e+02
I0506 12:08:33.798174 140299910223616 run_lib.py:158] step: 10800, eval_loss: 1.10750e+02
I0506 12:08:39.938570 140299910223616 run_lib.py:145] step: 10850, training_loss: 2.28825e+02
I0506 12:08:46.102913 140299910223616 run_lib.py:145] step: 10900, training_loss: 2.29538e+02
I0506 12:08:46.155468 140299910223616 run_lib.py:158] step: 10900, eval_loss: 1.65389e+02
I0506 12:08:52.356554 140299910223616 run_lib.py:145] step: 10950, training_loss: 1.44815e+02
I0506 12:08:58.705315 140299910223616 run_lib.py:145] step: 11000, training_loss: 2.08090e+02
I0506 12:08:58.752122 140299910223616 run_lib.py:158] step: 11000, eval_loss: 1.44596e+02
I0506 12:09:04.889516 140299910223616 run_lib.py:145] step: 11050, training_loss: 1.84369e+02
I0506 12:09:11.094651 140299910223616 run_lib.py:145] step: 11100, training_loss: 4.86191e+01
I0506 12:09:11.158980 140299910223616 run_lib.py:158] step: 11100, eval_loss: 2.02565e+02
I0506 12:09:17.524188 140299910223616 run_lib.py:145] step: 11150, training_loss: 1.35913e+02
I0506 12:09:23.655383 140299910223616 run_lib.py:145] step: 11200, training_loss: 8.66062e+01
I0506 12:09:23.707535 140299910223616 run_lib.py:158] step: 11200, eval_loss: 1.29031e+02
I0506 12:09:29.827062 140299910223616 run_lib.py:145] step: 11250, training_loss: 7.91241e+01
I0506 12:09:36.298336 140299910223616 run_lib.py:145] step: 11300, training_loss: 9.94289e+01
I0506 12:09:36.347175 140299910223616 run_lib.py:158] step: 11300, eval_loss: 1.93867e+02
I0506 12:09:42.507525 140299910223616 run_lib.py:145] step: 11350, training_loss: 1.57742e+02
I0506 12:09:48.718508 140299910223616 run_lib.py:145] step: 11400, training_loss: 1.82781e+02
I0506 12:09:48.781387 140299910223616 run_lib.py:158] step: 11400, eval_loss: 1.76024e+02
I0506 12:09:54.949731 140299910223616 run_lib.py:145] step: 11450, training_loss: 1.81998e+02
I0506 12:10:01.322929 140299910223616 run_lib.py:145] step: 11500, training_loss: 1.32655e+02
I0506 12:10:01.371748 140299910223616 run_lib.py:158] step: 11500, eval_loss: 1.68965e+02
I0506 12:10:07.551604 140299910223616 run_lib.py:145] step: 11550, training_loss: 1.58411e+02
I0506 12:10:13.732332 140299910223616 run_lib.py:145] step: 11600, training_loss: 2.66426e+02
I0506 12:10:13.794126 140299910223616 run_lib.py:158] step: 11600, eval_loss: 9.95320e+01
I0506 12:10:20.178970 140299910223616 run_lib.py:145] step: 11650, training_loss: 1.96987e+02
I0506 12:10:26.469053 140299910223616 run_lib.py:145] step: 11700, training_loss: 2.20462e+02
I0506 12:10:26.523090 140299910223616 run_lib.py:158] step: 11700, eval_loss: 1.66416e+02
I0506 12:10:32.716774 140299910223616 run_lib.py:145] step: 11750, training_loss: 2.20052e+02
I0506 12:10:38.927574 140299910223616 run_lib.py:145] step: 11800, training_loss: 9.22305e+01
I0506 12:10:38.982369 140299910223616 run_lib.py:158] step: 11800, eval_loss: 1.89454e+02
I0506 12:10:45.500524 140299910223616 run_lib.py:145] step: 11850, training_loss: 1.73605e+02
I0506 12:10:51.762590 140299910223616 run_lib.py:145] step: 11900, training_loss: 1.51127e+02
I0506 12:10:51.818456 140299910223616 run_lib.py:158] step: 11900, eval_loss: 1.35748e+02
I0506 12:10:58.032799 140299910223616 run_lib.py:145] step: 11950, training_loss: 1.62224e+02
I0506 12:11:04.431508 140299910223616 run_lib.py:145] step: 12000, training_loss: 1.38149e+02
I0506 12:11:04.482496 140299910223616 run_lib.py:158] step: 12000, eval_loss: 1.08859e+02
I0506 12:11:10.673756 140299910223616 run_lib.py:145] step: 12050, training_loss: 1.39460e+02
I0506 12:11:16.885090 140299910223616 run_lib.py:145] step: 12100, training_loss: 1.40681e+02
I0506 12:11:16.931574 140299910223616 run_lib.py:158] step: 12100, eval_loss: 1.67241e+02
I0506 12:11:23.077000 140299910223616 run_lib.py:145] step: 12150, training_loss: 1.36757e+02
I0506 12:11:29.463385 140299910223616 run_lib.py:145] step: 12200, training_loss: 1.00698e+02
I0506 12:11:29.515305 140299910223616 run_lib.py:158] step: 12200, eval_loss: 1.85619e+02
I0506 12:11:35.774011 140299910223616 run_lib.py:145] step: 12250, training_loss: 1.04004e+02
I0506 12:11:41.922003 140299910223616 run_lib.py:145] step: 12300, training_loss: 1.96582e+02
I0506 12:11:41.970753 140299910223616 run_lib.py:158] step: 12300, eval_loss: 1.75250e+02
I0506 12:11:48.483945 140299910223616 run_lib.py:145] step: 12350, training_loss: 1.63578e+02
I0506 12:11:54.605811 140299910223616 run_lib.py:145] step: 12400, training_loss: 2.02904e+02
I0506 12:11:54.657128 140299910223616 run_lib.py:158] step: 12400, eval_loss: 1.37317e+02
I0506 12:12:00.922263 140299910223616 run_lib.py:145] step: 12450, training_loss: 2.66803e+02
I0506 12:12:07.180351 140299910223616 run_lib.py:145] step: 12500, training_loss: 8.41486e+01
I0506 12:12:07.234200 140299910223616 run_lib.py:158] step: 12500, eval_loss: 1.24379e+02
I0506 12:12:13.794541 140299910223616 run_lib.py:145] step: 12550, training_loss: 1.57351e+02
I0506 12:12:20.405310 140299910223616 run_lib.py:145] step: 12600, training_loss: 1.36405e+02
I0506 12:12:20.457616 140299910223616 run_lib.py:158] step: 12600, eval_loss: 1.51426e+02
I0506 12:12:27.166732 140299910223616 run_lib.py:145] step: 12650, training_loss: 1.36209e+02
I0506 12:12:33.991720 140299910223616 run_lib.py:145] step: 12700, training_loss: 1.28568e+02
I0506 12:12:34.043608 140299910223616 run_lib.py:158] step: 12700, eval_loss: 1.23431e+02
I0506 12:12:40.270518 140299910223616 run_lib.py:145] step: 12750, training_loss: 1.75257e+02
I0506 12:12:46.604859 140299910223616 run_lib.py:145] step: 12800, training_loss: 1.52825e+02
I0506 12:12:46.660395 140299910223616 run_lib.py:158] step: 12800, eval_loss: 1.46770e+02
I0506 12:12:53.052824 140299910223616 run_lib.py:145] step: 12850, training_loss: 2.18039e+02
I0506 12:13:00.179502 140299910223616 run_lib.py:145] step: 12900, training_loss: 1.36872e+02
I0506 12:13:00.229822 140299910223616 run_lib.py:158] step: 12900, eval_loss: 1.01489e+02
I0506 12:13:06.869463 140299910223616 run_lib.py:145] step: 12950, training_loss: 1.54858e+02
I0506 12:13:13.435115 140299910223616 run_lib.py:145] step: 13000, training_loss: 1.20509e+02
I0506 12:13:13.494522 140299910223616 run_lib.py:158] step: 13000, eval_loss: 1.94613e+02
I0506 12:13:20.481626 140299910223616 run_lib.py:145] step: 13050, training_loss: 1.14615e+02
I0506 12:13:27.197919 140299910223616 run_lib.py:145] step: 13100, training_loss: 1.84891e+02
I0506 12:13:27.251672 140299910223616 run_lib.py:158] step: 13100, eval_loss: 1.47896e+02
I0506 12:13:34.041763 140299910223616 run_lib.py:145] step: 13150, training_loss: 1.73777e+02
I0506 12:13:40.707892 140299910223616 run_lib.py:145] step: 13200, training_loss: 1.57650e+02
I0506 12:13:40.770351 140299910223616 run_lib.py:158] step: 13200, eval_loss: 1.13466e+02
I0506 12:13:47.781059 140299910223616 run_lib.py:145] step: 13250, training_loss: 1.53151e+02
I0506 12:13:54.415647 140299910223616 run_lib.py:145] step: 13300, training_loss: 1.22264e+02
I0506 12:13:54.470894 140299910223616 run_lib.py:158] step: 13300, eval_loss: 2.02986e+02
I0506 12:14:01.083768 140299910223616 run_lib.py:145] step: 13350, training_loss: 1.40356e+02
I0506 12:14:08.104444 140299910223616 run_lib.py:145] step: 13400, training_loss: 1.18381e+02
I0506 12:14:08.162228 140299910223616 run_lib.py:158] step: 13400, eval_loss: 9.50462e+01
I0506 12:14:14.925548 140299910223616 run_lib.py:145] step: 13450, training_loss: 1.13651e+02
I0506 12:14:21.618517 140299910223616 run_lib.py:145] step: 13500, training_loss: 7.72932e+01
I0506 12:14:21.684843 140299910223616 run_lib.py:158] step: 13500, eval_loss: 1.35676e+02
I0506 12:14:28.464480 140299910223616 run_lib.py:145] step: 13550, training_loss: 1.98344e+02
I0506 12:14:35.321273 140299910223616 run_lib.py:145] step: 13600, training_loss: 2.08397e+02
I0506 12:14:35.376317 140299910223616 run_lib.py:158] step: 13600, eval_loss: 1.33768e+02
I0506 12:14:41.772775 140299910223616 run_lib.py:145] step: 13650, training_loss: 1.80025e+02
I0506 12:14:48.444829 140299910223616 run_lib.py:145] step: 13700, training_loss: 1.67365e+02
I0506 12:14:48.500231 140299910223616 run_lib.py:158] step: 13700, eval_loss: 1.50756e+02
I0506 12:14:55.539164 140299910223616 run_lib.py:145] step: 13750, training_loss: 1.60427e+02
I0506 12:15:02.159992 140299910223616 run_lib.py:145] step: 13800, training_loss: 1.57008e+02
I0506 12:15:02.219552 140299910223616 run_lib.py:158] step: 13800, eval_loss: 2.16523e+02
I0506 12:15:09.043308 140299910223616 run_lib.py:145] step: 13850, training_loss: 1.30333e+02
I0506 12:15:15.662909 140299910223616 run_lib.py:145] step: 13900, training_loss: 1.19430e+02
I0506 12:15:15.723155 140299910223616 run_lib.py:158] step: 13900, eval_loss: 1.52765e+02
I0506 12:15:22.738924 140299910223616 run_lib.py:145] step: 13950, training_loss: 1.73851e+02
I0506 12:15:29.316077 140299910223616 run_lib.py:145] step: 14000, training_loss: 1.30091e+02
I0506 12:15:29.372410 140299910223616 run_lib.py:158] step: 14000, eval_loss: 1.47689e+02
I0506 12:15:36.067563 140299910223616 run_lib.py:145] step: 14050, training_loss: 2.03380e+02
I0506 12:15:42.937623 140299910223616 run_lib.py:145] step: 14100, training_loss: 1.19207e+02
I0506 12:15:42.992579 140299910223616 run_lib.py:158] step: 14100, eval_loss: 1.64230e+02
I0506 12:15:49.480260 140299910223616 run_lib.py:145] step: 14150, training_loss: 1.60575e+02
I0506 12:15:55.997931 140299910223616 run_lib.py:145] step: 14200, training_loss: 2.10034e+02
I0506 12:15:56.056419 140299910223616 run_lib.py:158] step: 14200, eval_loss: 1.64313e+02
I0506 12:16:02.743581 140299910223616 run_lib.py:145] step: 14250, training_loss: 1.33481e+02
I0506 12:16:09.407379 140299910223616 run_lib.py:145] step: 14300, training_loss: 1.59595e+02
I0506 12:16:09.471737 140299910223616 run_lib.py:158] step: 14300, eval_loss: 1.20526e+02
I0506 12:16:16.242433 140299910223616 run_lib.py:145] step: 14350, training_loss: 1.44270e+02
I0506 12:16:22.927075 140299910223616 run_lib.py:145] step: 14400, training_loss: 1.60112e+02
I0506 12:16:22.979584 140299910223616 run_lib.py:158] step: 14400, eval_loss: 1.68314e+02
I0506 12:16:29.872686 140299910223616 run_lib.py:145] step: 14450, training_loss: 2.10536e+02
I0506 12:16:36.481512 140299910223616 run_lib.py:145] step: 14500, training_loss: 1.35361e+02
I0506 12:16:36.539979 140299910223616 run_lib.py:158] step: 14500, eval_loss: 1.11563e+02
I0506 12:16:43.255348 140299910223616 run_lib.py:145] step: 14550, training_loss: 1.64848e+02
I0506 12:16:50.183758 140299910223616 run_lib.py:145] step: 14600, training_loss: 1.80915e+02
I0506 12:16:50.242885 140299910223616 run_lib.py:158] step: 14600, eval_loss: 1.40540e+02
I0506 12:16:57.016596 140299910223616 run_lib.py:145] step: 14650, training_loss: 1.03359e+02
I0506 12:17:03.702447 140299910223616 run_lib.py:145] step: 14700, training_loss: 2.13382e+02
I0506 12:17:03.762651 140299910223616 run_lib.py:158] step: 14700, eval_loss: 1.41109e+02
I0506 12:17:10.665894 140299910223616 run_lib.py:145] step: 14750, training_loss: 1.43973e+02
I0506 12:17:17.365987 140299910223616 run_lib.py:145] step: 14800, training_loss: 2.65131e+02
I0506 12:17:17.426827 140299910223616 run_lib.py:158] step: 14800, eval_loss: 1.75628e+02
I0506 12:17:24.202792 140299910223616 run_lib.py:145] step: 14850, training_loss: 1.36121e+02
I0506 12:17:30.832985 140299910223616 run_lib.py:145] step: 14900, training_loss: 1.15998e+02
I0506 12:17:30.889631 140299910223616 run_lib.py:158] step: 14900, eval_loss: 1.62591e+02
I0506 12:17:37.853504 140299910223616 run_lib.py:145] step: 14950, training_loss: 1.74031e+02
I0506 12:17:44.681280 140299910223616 run_lib.py:145] step: 15000, training_loss: 1.47240e+02
I0506 12:17:44.735830 140299910223616 run_lib.py:158] step: 15000, eval_loss: 1.25482e+02
I0506 12:17:51.446342 140299910223616 run_lib.py:145] step: 15050, training_loss: 1.79895e+02
I0506 12:17:57.980691 140299910223616 run_lib.py:145] step: 15100, training_loss: 1.64676e+02
I0506 12:17:58.033001 140299910223616 run_lib.py:158] step: 15100, eval_loss: 1.42161e+02
I0506 12:18:05.003822 140299910223616 run_lib.py:145] step: 15150, training_loss: 1.03386e+02
I0506 12:18:11.725594 140299910223616 run_lib.py:145] step: 15200, training_loss: 2.14219e+02
I0506 12:18:11.781592 140299910223616 run_lib.py:158] step: 15200, eval_loss: 2.04660e+02
I0506 12:18:18.384851 140299910223616 run_lib.py:145] step: 15250, training_loss: 1.24031e+02
I0506 12:18:25.278054 140299910223616 run_lib.py:145] step: 15300, training_loss: 9.13340e+01
I0506 12:18:25.330673 140299910223616 run_lib.py:158] step: 15300, eval_loss: 1.35501e+02
I0506 12:18:31.941001 140299910223616 run_lib.py:145] step: 15350, training_loss: 1.07551e+02
I0506 12:18:38.794921 140299910223616 run_lib.py:145] step: 15400, training_loss: 2.00721e+02
I0506 12:18:38.853520 140299910223616 run_lib.py:158] step: 15400, eval_loss: 1.98698e+02
I0506 12:18:45.541077 140299910223616 run_lib.py:145] step: 15450, training_loss: 8.45139e+01
I0506 12:18:52.484793 140299910223616 run_lib.py:145] step: 15500, training_loss: 1.10139e+02
I0506 12:18:52.546921 140299910223616 run_lib.py:158] step: 15500, eval_loss: 1.57498e+02
I0506 12:18:59.296727 140299910223616 run_lib.py:145] step: 15550, training_loss: 1.26519e+02
I0506 12:19:06.096921 140299910223616 run_lib.py:145] step: 15600, training_loss: 2.20773e+02
I0506 12:19:06.148383 140299910223616 run_lib.py:158] step: 15600, eval_loss: 1.03356e+02
I0506 12:19:13.304314 140299910223616 run_lib.py:145] step: 15650, training_loss: 2.09684e+02
I0506 12:19:20.043573 140299910223616 run_lib.py:145] step: 15700, training_loss: 1.81309e+02
I0506 12:19:20.109806 140299910223616 run_lib.py:158] step: 15700, eval_loss: 1.18461e+02
I0506 12:19:26.698844 140299910223616 run_lib.py:145] step: 15750, training_loss: 1.59217e+02
I0506 12:19:33.364578 140299910223616 run_lib.py:145] step: 15800, training_loss: 1.38405e+02
I0506 12:19:33.419268 140299910223616 run_lib.py:158] step: 15800, eval_loss: 1.35263e+02
I0506 12:19:40.456800 140299910223616 run_lib.py:145] step: 15850, training_loss: 1.03576e+02
I0506 12:19:47.041791 140299910223616 run_lib.py:145] step: 15900, training_loss: 1.81367e+02
I0506 12:19:47.095359 140299910223616 run_lib.py:158] step: 15900, eval_loss: 1.58142e+02
I0506 12:19:53.647580 140299910223616 run_lib.py:145] step: 15950, training_loss: 1.36810e+02
I0506 12:20:00.744809 140299910223616 run_lib.py:145] step: 16000, training_loss: 9.64948e+01
I0506 12:20:00.801287 140299910223616 run_lib.py:158] step: 16000, eval_loss: 1.25264e+02
I0506 12:20:07.254583 140299910223616 run_lib.py:145] step: 16050, training_loss: 8.44721e+01
I0506 12:20:13.950441 140299910223616 run_lib.py:145] step: 16100, training_loss: 2.10585e+02
I0506 12:20:14.010700 140299910223616 run_lib.py:158] step: 16100, eval_loss: 2.04740e+02
I0506 12:20:20.704879 140299910223616 run_lib.py:145] step: 16150, training_loss: 1.18253e+02
I0506 12:20:27.650660 140299910223616 run_lib.py:145] step: 16200, training_loss: 1.36811e+02
I0506 12:20:27.709031 140299910223616 run_lib.py:158] step: 16200, eval_loss: 8.24806e+01
I0506 12:20:34.529706 140299910223616 run_lib.py:145] step: 16250, training_loss: 2.11499e+02
I0506 12:20:41.126525 140299910223616 run_lib.py:145] step: 16300, training_loss: 1.04909e+02
I0506 12:20:41.190816 140299910223616 run_lib.py:158] step: 16300, eval_loss: 8.50672e+01
I0506 12:20:48.243799 140299910223616 run_lib.py:145] step: 16350, training_loss: 1.25565e+02
I0506 12:20:54.724715 140299910223616 run_lib.py:145] step: 16400, training_loss: 1.06411e+02
I0506 12:20:54.780532 140299910223616 run_lib.py:158] step: 16400, eval_loss: 1.55390e+02
I0506 12:21:01.619483 140299910223616 run_lib.py:145] step: 16450, training_loss: 8.58583e+01
I0506 12:21:08.213257 140299910223616 run_lib.py:145] step: 16500, training_loss: 9.70992e+01
I0506 12:21:08.279265 140299910223616 run_lib.py:158] step: 16500, eval_loss: 1.30781e+02
I0506 12:21:15.255216 140299910223616 run_lib.py:145] step: 16550, training_loss: 1.54014e+02
I0506 12:21:22.000233 140299910223616 run_lib.py:145] step: 16600, training_loss: 1.55663e+02
I0506 12:21:22.056477 140299910223616 run_lib.py:158] step: 16600, eval_loss: 1.43543e+02
I0506 12:21:28.886892 140299910223616 run_lib.py:145] step: 16650, training_loss: 1.56003e+02
I0506 12:21:35.588640 140299910223616 run_lib.py:145] step: 16700, training_loss: 1.03868e+02
I0506 12:21:35.645797 140299910223616 run_lib.py:158] step: 16700, eval_loss: 1.21499e+02
I0506 12:21:42.461660 140299910223616 run_lib.py:145] step: 16750, training_loss: 1.35951e+02
I0506 12:21:49.100679 140299910223616 run_lib.py:145] step: 16800, training_loss: 9.34240e+01
I0506 12:21:49.156087 140299910223616 run_lib.py:158] step: 16800, eval_loss: 2.11942e+02
I0506 12:21:55.875787 140299910223616 run_lib.py:145] step: 16850, training_loss: 2.02988e+02
I0506 12:22:02.949760 140299910223616 run_lib.py:145] step: 16900, training_loss: 6.87418e+01
I0506 12:22:03.003598 140299910223616 run_lib.py:158] step: 16900, eval_loss: 1.10980e+02
I0506 12:22:09.628177 140299910223616 run_lib.py:145] step: 16950, training_loss: 2.08098e+02
I0506 12:22:16.297111 140299910223616 run_lib.py:145] step: 17000, training_loss: 1.92440e+02
I0506 12:22:16.350939 140299910223616 run_lib.py:158] step: 17000, eval_loss: 1.92549e+02
I0506 12:22:23.212957 140299910223616 run_lib.py:145] step: 17050, training_loss: 1.10457e+02
I0506 12:22:30.028731 140299910223616 run_lib.py:145] step: 17100, training_loss: 1.61900e+02
I0506 12:22:30.091663 140299910223616 run_lib.py:158] step: 17100, eval_loss: 1.02156e+02
I0506 12:22:36.736898 140299910223616 run_lib.py:145] step: 17150, training_loss: 1.27036e+02
I0506 12:22:43.272097 140299910223616 run_lib.py:145] step: 17200, training_loss: 1.55120e+02
I0506 12:22:43.329939 140299910223616 run_lib.py:158] step: 17200, eval_loss: 1.62436e+02
I0506 12:22:50.389806 140299910223616 run_lib.py:145] step: 17250, training_loss: 1.58725e+02
I0506 12:22:56.899375 140299910223616 run_lib.py:145] step: 17300, training_loss: 1.59893e+02
I0506 12:22:56.957840 140299910223616 run_lib.py:158] step: 17300, eval_loss: 1.76991e+02
I0506 12:23:03.828576 140299910223616 run_lib.py:145] step: 17350, training_loss: 1.51262e+02
I0506 12:23:10.902259 140299910223616 run_lib.py:145] step: 17400, training_loss: 1.39880e+02
I0506 12:23:10.962285 140299910223616 run_lib.py:158] step: 17400, eval_loss: 2.04052e+02
I0506 12:23:17.601494 140299910223616 run_lib.py:145] step: 17450, training_loss: 1.81583e+02
I0506 12:23:24.299929 140299910223616 run_lib.py:145] step: 17500, training_loss: 1.56227e+02
I0506 12:23:24.354279 140299910223616 run_lib.py:158] step: 17500, eval_loss: 1.43118e+02
I0506 12:23:31.038811 140299910223616 run_lib.py:145] step: 17550, training_loss: 1.24291e+02
I0506 12:23:37.867763 140299910223616 run_lib.py:145] step: 17600, training_loss: 1.03558e+02
I0506 12:23:37.929822 140299910223616 run_lib.py:158] step: 17600, eval_loss: 1.65352e+02
I0506 12:23:44.723667 140299910223616 run_lib.py:145] step: 17650, training_loss: 1.56106e+02
I0506 12:23:51.594628 140299910223616 run_lib.py:145] step: 17700, training_loss: 1.16274e+02
I0506 12:23:51.652010 140299910223616 run_lib.py:158] step: 17700, eval_loss: 8.91766e+01
I0506 12:23:58.692558 140299910223616 run_lib.py:145] step: 17750, training_loss: 8.47241e+01
I0506 12:24:05.390696 140299910223616 run_lib.py:145] step: 17800, training_loss: 1.50623e+02
I0506 12:24:05.446797 140299910223616 run_lib.py:158] step: 17800, eval_loss: 1.77394e+02
I0506 12:24:12.189713 140299910223616 run_lib.py:145] step: 17850, training_loss: 2.45341e+02
I0506 12:24:18.753195 140299910223616 run_lib.py:145] step: 17900, training_loss: 1.37389e+02
I0506 12:24:18.804998 140299910223616 run_lib.py:158] step: 17900, eval_loss: 9.60802e+01
I0506 12:24:25.879220 140299910223616 run_lib.py:145] step: 17950, training_loss: 1.56501e+02
I0506 12:24:32.620595 140299910223616 run_lib.py:145] step: 18000, training_loss: 1.43667e+02
I0506 12:24:32.675032 140299910223616 run_lib.py:158] step: 18000, eval_loss: 1.14272e+02
I0506 12:24:39.275136 140299910223616 run_lib.py:145] step: 18050, training_loss: 1.31846e+02
I0506 12:24:46.227123 140299910223616 run_lib.py:145] step: 18100, training_loss: 1.94176e+02
I0506 12:24:46.284695 140299910223616 run_lib.py:158] step: 18100, eval_loss: 1.25801e+02
I0506 12:24:53.110980 140299910223616 run_lib.py:145] step: 18150, training_loss: 1.52273e+02
I0506 12:24:59.898765 140299910223616 run_lib.py:145] step: 18200, training_loss: 1.33393e+02
I0506 12:24:59.958632 140299910223616 run_lib.py:158] step: 18200, eval_loss: 1.17865e+02
I0506 12:25:06.685130 140299910223616 run_lib.py:145] step: 18250, training_loss: 2.05896e+02
I0506 12:25:13.700900 140299910223616 run_lib.py:145] step: 18300, training_loss: 1.28277e+02
I0506 12:25:13.755772 140299910223616 run_lib.py:158] step: 18300, eval_loss: 1.68932e+02
I0506 12:25:20.690656 140299910223616 run_lib.py:145] step: 18350, training_loss: 2.36626e+02
I0506 12:25:27.156909 140299910223616 run_lib.py:145] step: 18400, training_loss: 1.11230e+02
I0506 12:25:27.217480 140299910223616 run_lib.py:158] step: 18400, eval_loss: 1.32177e+02
I0506 12:25:34.239557 140299910223616 run_lib.py:145] step: 18450, training_loss: 1.87320e+02
I0506 12:25:40.907413 140299910223616 run_lib.py:145] step: 18500, training_loss: 1.78784e+02
I0506 12:25:40.973641 140299910223616 run_lib.py:158] step: 18500, eval_loss: 1.50667e+02
I0506 12:25:47.764995 140299910223616 run_lib.py:145] step: 18550, training_loss: 1.62478e+02
I0506 12:25:54.485953 140299910223616 run_lib.py:145] step: 18600, training_loss: 1.32775e+02
I0506 12:25:54.539700 140299910223616 run_lib.py:158] step: 18600, eval_loss: 1.91239e+02
I0506 12:26:01.535118 140299910223616 run_lib.py:145] step: 18650, training_loss: 1.26806e+02
I0506 12:26:08.317066 140299910223616 run_lib.py:145] step: 18700, training_loss: 2.04358e+02
I0506 12:26:08.375267 140299910223616 run_lib.py:158] step: 18700, eval_loss: 1.06167e+02
I0506 12:26:15.069106 140299910223616 run_lib.py:145] step: 18750, training_loss: 1.35148e+02
I0506 12:26:21.877711 140299910223616 run_lib.py:145] step: 18800, training_loss: 1.41410e+02
I0506 12:26:21.944789 140299910223616 run_lib.py:158] step: 18800, eval_loss: 1.11671e+02
I0506 12:26:28.643441 140299910223616 run_lib.py:145] step: 18850, training_loss: 1.70818e+02
I0506 12:26:35.259961 140299910223616 run_lib.py:145] step: 18900, training_loss: 2.07012e+02
I0506 12:26:35.316760 140299910223616 run_lib.py:158] step: 18900, eval_loss: 1.92315e+02
I0506 12:26:41.899070 140299910223616 run_lib.py:145] step: 18950, training_loss: 9.88349e+01
I0506 12:26:48.872954 140299910223616 run_lib.py:145] step: 19000, training_loss: 2.39389e+02
I0506 12:26:48.933634 140299910223616 run_lib.py:158] step: 19000, eval_loss: 1.71661e+02
I0506 12:26:55.555705 140299910223616 run_lib.py:145] step: 19050, training_loss: 1.34627e+02
I0506 12:27:02.379773 140299910223616 run_lib.py:145] step: 19100, training_loss: 9.96032e+01
I0506 12:27:02.435688 140299910223616 run_lib.py:158] step: 19100, eval_loss: 1.40399e+02
I0506 12:27:09.354937 140299910223616 run_lib.py:145] step: 19150, training_loss: 1.22797e+02
I0506 12:27:16.195699 140299910223616 run_lib.py:145] step: 19200, training_loss: 1.46688e+02
I0506 12:27:16.262600 140299910223616 run_lib.py:158] step: 19200, eval_loss: 1.61071e+02
I0506 12:27:23.095847 140299910223616 run_lib.py:145] step: 19250, training_loss: 1.90749e+02
I0506 12:27:29.840807 140299910223616 run_lib.py:145] step: 19300, training_loss: 1.37392e+02
I0506 12:27:29.893397 140299910223616 run_lib.py:158] step: 19300, eval_loss: 1.09142e+02
I0506 12:27:36.713433 140299910223616 run_lib.py:145] step: 19350, training_loss: 1.44749e+02
I0506 12:27:43.260132 140299910223616 run_lib.py:145] step: 19400, training_loss: 1.38200e+02
I0506 12:27:43.319879 140299910223616 run_lib.py:158] step: 19400, eval_loss: 1.86461e+02
I0506 12:27:50.102780 140299910223616 run_lib.py:145] step: 19450, training_loss: 1.36863e+02
I0506 12:27:56.873608 140299910223616 run_lib.py:145] step: 19500, training_loss: 1.27371e+02
I0506 12:27:56.926564 140299910223616 run_lib.py:158] step: 19500, eval_loss: 1.37592e+02
I0506 12:28:03.566827 140299910223616 run_lib.py:145] step: 19550, training_loss: 2.37868e+02
I0506 12:28:10.152905 140299910223616 run_lib.py:145] step: 19600, training_loss: 8.61722e+01
I0506 12:28:10.207210 140299910223616 run_lib.py:158] step: 19600, eval_loss: 1.44923e+02
I0506 12:28:17.165433 140299910223616 run_lib.py:145] step: 19650, training_loss: 1.35517e+02
I0506 12:28:23.974591 140299910223616 run_lib.py:145] step: 19700, training_loss: 1.31699e+02
I0506 12:28:24.033781 140299910223616 run_lib.py:158] step: 19700, eval_loss: 9.17733e+01
I0506 12:28:30.576992 140299910223616 run_lib.py:145] step: 19750, training_loss: 1.20903e+02
I0506 12:28:37.316891 140299910223616 run_lib.py:145] step: 19800, training_loss: 1.91526e+02
I0506 12:28:37.374786 140299910223616 run_lib.py:158] step: 19800, eval_loss: 1.85569e+02
I0506 12:28:44.438699 140299910223616 run_lib.py:145] step: 19850, training_loss: 7.75946e+01
I0506 12:28:50.971683 140299910223616 run_lib.py:145] step: 19900, training_loss: 1.11146e+02
I0506 12:28:51.028617 140299910223616 run_lib.py:158] step: 19900, eval_loss: 8.82822e+01
I0506 12:28:57.908288 140299910223616 run_lib.py:145] step: 19950, training_loss: 1.54760e+02
I0506 12:29:04.651575 140299910223616 run_lib.py:145] step: 20000, training_loss: 1.24421e+02
I0506 12:29:04.893372 140299910223616 run_lib.py:158] step: 20000, eval_loss: 1.00982e+02
I0506 12:29:11.754830 140299910223616 run_lib.py:145] step: 20050, training_loss: 1.69192e+02
I0506 12:29:18.598457 140299910223616 run_lib.py:145] step: 20100, training_loss: 1.38472e+02
I0506 12:29:18.657569 140299910223616 run_lib.py:158] step: 20100, eval_loss: 7.62090e+01
I0506 12:29:25.259752 140299910223616 run_lib.py:145] step: 20150, training_loss: 1.12643e+02
I0506 12:29:32.175260 140299910223616 run_lib.py:145] step: 20200, training_loss: 1.42467e+02
I0506 12:29:32.232634 140299910223616 run_lib.py:158] step: 20200, eval_loss: 1.27906e+02
I0506 12:29:39.010716 140299910223616 run_lib.py:145] step: 20250, training_loss: 1.08761e+02
I0506 12:29:45.681080 140299910223616 run_lib.py:145] step: 20300, training_loss: 1.85334e+02
I0506 12:29:45.737649 140299910223616 run_lib.py:158] step: 20300, eval_loss: 9.31840e+01
I0506 12:29:52.797953 140299910223616 run_lib.py:145] step: 20350, training_loss: 1.17993e+02
I0506 12:29:59.513443 140299910223616 run_lib.py:145] step: 20400, training_loss: 1.22307e+02
I0506 12:29:59.565821 140299910223616 run_lib.py:158] step: 20400, eval_loss: 9.46945e+01
I0506 12:30:06.371731 140299910223616 run_lib.py:145] step: 20450, training_loss: 1.83443e+02
I0506 12:30:13.171661 140299910223616 run_lib.py:145] step: 20500, training_loss: 1.66461e+02
I0506 12:30:13.228575 140299910223616 run_lib.py:158] step: 20500, eval_loss: 1.47071e+02
I0506 12:30:19.962148 140299910223616 run_lib.py:145] step: 20550, training_loss: 1.49265e+02
I0506 12:30:26.653155 140299910223616 run_lib.py:145] step: 20600, training_loss: 9.73057e+01
I0506 12:30:26.713818 140299910223616 run_lib.py:158] step: 20600, eval_loss: 1.08151e+02
I0506 12:30:33.201774 140299910223616 run_lib.py:145] step: 20650, training_loss: 1.03283e+02
I0506 12:30:40.309618 140299910223616 run_lib.py:145] step: 20700, training_loss: 1.40688e+02
I0506 12:30:40.364059 140299910223616 run_lib.py:158] step: 20700, eval_loss: 7.19927e+01
I0506 12:30:46.986892 140299910223616 run_lib.py:145] step: 20750, training_loss: 1.31116e+02
I0506 12:30:53.743528 140299910223616 run_lib.py:145] step: 20800, training_loss: 1.48702e+02
I0506 12:30:53.797224 140299910223616 run_lib.py:158] step: 20800, eval_loss: 1.85353e+02
I0506 12:31:00.274546 140299910223616 run_lib.py:145] step: 20850, training_loss: 1.77862e+02
I0506 12:31:07.480899 140299910223616 run_lib.py:145] step: 20900, training_loss: 1.49526e+02
I0506 12:31:07.542876 140299910223616 run_lib.py:158] step: 20900, eval_loss: 1.05840e+02
I0506 12:31:13.982412 140299910223616 run_lib.py:145] step: 20950, training_loss: 1.35890e+02
I0506 12:31:20.623335 140299910223616 run_lib.py:145] step: 21000, training_loss: 1.71708e+02
I0506 12:31:20.675715 140299910223616 run_lib.py:158] step: 21000, eval_loss: 1.90786e+02
I0506 12:31:27.519988 140299910223616 run_lib.py:145] step: 21050, training_loss: 1.42074e+02
I0506 12:31:34.295594 140299910223616 run_lib.py:145] step: 21100, training_loss: 1.24582e+02
I0506 12:31:34.348580 140299910223616 run_lib.py:158] step: 21100, eval_loss: 8.96402e+01
I0506 12:31:41.197192 140299910223616 run_lib.py:145] step: 21150, training_loss: 1.88025e+02
I0506 12:31:47.819840 140299910223616 run_lib.py:145] step: 21200, training_loss: 9.99759e+01
I0506 12:31:47.874189 140299910223616 run_lib.py:158] step: 21200, eval_loss: 1.25219e+02
I0506 12:31:54.818707 140299910223616 run_lib.py:145] step: 21250, training_loss: 1.50312e+02
I0506 12:32:01.310768 140299910223616 run_lib.py:145] step: 21300, training_loss: 1.79369e+02
I0506 12:32:01.367990 140299910223616 run_lib.py:158] step: 21300, eval_loss: 2.20271e+02
I0506 12:32:08.205132 140299910223616 run_lib.py:145] step: 21350, training_loss: 1.33925e+02
I0506 12:32:15.038242 140299910223616 run_lib.py:145] step: 21400, training_loss: 1.72666e+02
I0506 12:32:15.096832 140299910223616 run_lib.py:158] step: 21400, eval_loss: 2.05808e+02
I0506 12:32:21.863514 140299910223616 run_lib.py:145] step: 21450, training_loss: 1.18087e+02
I0506 12:32:28.622143 140299910223616 run_lib.py:145] step: 21500, training_loss: 1.63374e+02
I0506 12:32:28.681808 140299910223616 run_lib.py:158] step: 21500, eval_loss: 2.19764e+02
I0506 12:32:35.387308 140299910223616 run_lib.py:145] step: 21550, training_loss: 1.18853e+02
I0506 12:32:42.306001 140299910223616 run_lib.py:145] step: 21600, training_loss: 1.15318e+02
I0506 12:32:42.358902 140299910223616 run_lib.py:158] step: 21600, eval_loss: 1.65039e+02
I0506 12:32:49.075572 140299910223616 run_lib.py:145] step: 21650, training_loss: 1.53716e+02
I0506 12:32:55.796729 140299910223616 run_lib.py:145] step: 21700, training_loss: 1.04715e+02
I0506 12:32:55.853963 140299910223616 run_lib.py:158] step: 21700, eval_loss: 1.44991e+02
I0506 12:33:02.732350 140299910223616 run_lib.py:145] step: 21750, training_loss: 1.41668e+02
I0506 12:33:09.219761 140299910223616 run_lib.py:145] step: 21800, training_loss: 6.01528e+01
I0506 12:33:09.276323 140299910223616 run_lib.py:158] step: 21800, eval_loss: 1.24764e+02
I0506 12:33:15.900101 140299910223616 run_lib.py:145] step: 21850, training_loss: 1.62466e+02
I0506 12:33:22.614385 140299910223616 run_lib.py:145] step: 21900, training_loss: 1.28479e+02
I0506 12:33:22.670665 140299910223616 run_lib.py:158] step: 21900, eval_loss: 1.76820e+02
I0506 12:33:29.732886 140299910223616 run_lib.py:145] step: 21950, training_loss: 1.33636e+02
I0506 12:33:36.602036 140299910223616 run_lib.py:145] step: 22000, training_loss: 1.53364e+02
I0506 12:33:36.660379 140299910223616 run_lib.py:158] step: 22000, eval_loss: 1.23615e+02
I0506 12:33:43.481555 140299910223616 run_lib.py:145] step: 22050, training_loss: 1.02489e+02
I0506 12:33:50.434647 140299910223616 run_lib.py:145] step: 22100, training_loss: 1.51017e+02
I0506 12:33:50.489429 140299910223616 run_lib.py:158] step: 22100, eval_loss: 1.28330e+02
I0506 12:33:57.045676 140299910223616 run_lib.py:145] step: 22150, training_loss: 1.67152e+02
I0506 12:34:03.648590 140299910223616 run_lib.py:145] step: 22200, training_loss: 1.61538e+02
I0506 12:34:03.702554 140299910223616 run_lib.py:158] step: 22200, eval_loss: 9.68565e+01
I0506 12:34:10.439288 140299910223616 run_lib.py:145] step: 22250, training_loss: 1.44891e+02
I0506 12:34:17.428661 140299910223616 run_lib.py:145] step: 22300, training_loss: 1.60260e+02
I0506 12:34:17.484408 140299910223616 run_lib.py:158] step: 22300, eval_loss: 1.37411e+02
I0506 12:34:24.048444 140299910223616 run_lib.py:145] step: 22350, training_loss: 1.10983e+02
I0506 12:34:30.919471 140299910223616 run_lib.py:145] step: 22400, training_loss: 1.41913e+02
I0506 12:34:30.973167 140299910223616 run_lib.py:158] step: 22400, eval_loss: 1.43934e+02
I0506 12:34:37.814476 140299910223616 run_lib.py:145] step: 22450, training_loss: 9.69059e+01
I0506 12:34:44.540718 140299910223616 run_lib.py:145] step: 22500, training_loss: 1.23271e+02
I0506 12:34:44.603000 140299910223616 run_lib.py:158] step: 22500, eval_loss: 1.85506e+02
I0506 12:34:51.387025 140299910223616 run_lib.py:145] step: 22550, training_loss: 1.58619e+02
I0506 12:34:57.914800 140299910223616 run_lib.py:145] step: 22600, training_loss: 1.58587e+02
I0506 12:34:57.974243 140299910223616 run_lib.py:158] step: 22600, eval_loss: 1.52991e+02
I0506 12:35:04.867413 140299910223616 run_lib.py:145] step: 22650, training_loss: 1.52206e+02
I0506 12:35:11.398898 140299910223616 run_lib.py:145] step: 22700, training_loss: 1.74563e+02
I0506 12:35:11.456205 140299910223616 run_lib.py:158] step: 22700, eval_loss: 1.27959e+02
I0506 12:35:18.068012 140299910223616 run_lib.py:145] step: 22750, training_loss: 2.04936e+02
I0506 12:35:25.096268 140299910223616 run_lib.py:145] step: 22800, training_loss: 1.79269e+02
I0506 12:35:25.158013 140299910223616 run_lib.py:158] step: 22800, eval_loss: 1.22583e+02
I0506 12:35:31.649880 140299910223616 run_lib.py:145] step: 22850, training_loss: 1.53484e+02
I0506 12:35:38.486131 140299910223616 run_lib.py:145] step: 22900, training_loss: 1.90023e+02
I0506 12:35:38.548046 140299910223616 run_lib.py:158] step: 22900, eval_loss: 1.86818e+02
I0506 12:35:45.399670 140299910223616 run_lib.py:145] step: 22950, training_loss: 1.31081e+02
I0506 12:35:52.241919 140299910223616 run_lib.py:145] step: 23000, training_loss: 1.02690e+02
I0506 12:35:52.304336 140299910223616 run_lib.py:158] step: 23000, eval_loss: 1.00970e+02
I0506 12:35:58.792682 140299910223616 run_lib.py:145] step: 23050, training_loss: 7.52547e+01
I0506 12:36:05.779273 140299910223616 run_lib.py:145] step: 23100, training_loss: 1.51211e+02
I0506 12:36:05.838847 140299910223616 run_lib.py:158] step: 23100, eval_loss: 1.51685e+02
I0506 12:36:12.742891 140299910223616 run_lib.py:145] step: 23150, training_loss: 1.43852e+02
I0506 12:36:19.526106 140299910223616 run_lib.py:145] step: 23200, training_loss: 1.00272e+02
I0506 12:36:19.590184 140299910223616 run_lib.py:158] step: 23200, eval_loss: 1.06173e+02
I0506 12:36:26.248127 140299910223616 run_lib.py:145] step: 23250, training_loss: 2.30649e+02
I0506 12:36:33.233820 140299910223616 run_lib.py:145] step: 23300, training_loss: 1.10911e+02
I0506 12:36:33.292483 140299910223616 run_lib.py:158] step: 23300, eval_loss: 1.62178e+02
I0506 12:36:39.848945 140299910223616 run_lib.py:145] step: 23350, training_loss: 1.81404e+02
I0506 12:36:46.782657 140299910223616 run_lib.py:145] step: 23400, training_loss: 1.95768e+02
I0506 12:36:46.835331 140299910223616 run_lib.py:158] step: 23400, eval_loss: 7.47257e+01
I0506 12:36:53.719711 140299910223616 run_lib.py:145] step: 23450, training_loss: 1.09105e+02
I0506 12:37:00.649033 140299910223616 run_lib.py:145] step: 23500, training_loss: 1.72824e+02
I0506 12:37:00.703878 140299910223616 run_lib.py:158] step: 23500, eval_loss: 6.33193e+01
I0506 12:37:07.274844 140299910223616 run_lib.py:145] step: 23550, training_loss: 1.54171e+02
I0506 12:37:14.099097 140299910223616 run_lib.py:145] step: 23600, training_loss: 1.31054e+02
I0506 12:37:14.155601 140299910223616 run_lib.py:158] step: 23600, eval_loss: 1.71606e+02
I0506 12:37:21.034131 140299910223616 run_lib.py:145] step: 23650, training_loss: 1.94693e+02
I0506 12:37:27.709293 140299910223616 run_lib.py:145] step: 23700, training_loss: 1.75351e+02
I0506 12:37:27.764124 140299910223616 run_lib.py:158] step: 23700, eval_loss: 1.28967e+02
I0506 12:37:34.614834 140299910223616 run_lib.py:145] step: 23750, training_loss: 1.92500e+02
I0506 12:37:41.116157 140299910223616 run_lib.py:145] step: 23800, training_loss: 1.57441e+02
I0506 12:37:41.171165 140299910223616 run_lib.py:158] step: 23800, eval_loss: 1.31438e+02
I0506 12:37:48.173360 140299910223616 run_lib.py:145] step: 23850, training_loss: 1.21979e+02
I0506 12:37:54.871493 140299910223616 run_lib.py:145] step: 23900, training_loss: 1.16010e+02
I0506 12:37:54.929223 140299910223616 run_lib.py:158] step: 23900, eval_loss: 1.23343e+02
I0506 12:38:01.268279 140299910223616 run_lib.py:145] step: 23950, training_loss: 1.21510e+02
I0506 12:38:08.239380 140299910223616 run_lib.py:145] step: 24000, training_loss: 1.47027e+02
I0506 12:38:08.300355 140299910223616 run_lib.py:158] step: 24000, eval_loss: 2.05415e+02
I0506 12:38:15.118637 140299910223616 run_lib.py:145] step: 24050, training_loss: 1.87305e+02
I0506 12:38:21.810692 140299910223616 run_lib.py:145] step: 24100, training_loss: 1.34297e+02
I0506 12:38:21.871453 140299910223616 run_lib.py:158] step: 24100, eval_loss: 1.39792e+02
I0506 12:38:28.414358 140299910223616 run_lib.py:145] step: 24150, training_loss: 1.55478e+02
I0506 12:38:35.333302 140299910223616 run_lib.py:145] step: 24200, training_loss: 1.58286e+02
I0506 12:38:35.392724 140299910223616 run_lib.py:158] step: 24200, eval_loss: 1.02838e+02
I0506 12:38:42.034405 140299910223616 run_lib.py:145] step: 24250, training_loss: 2.17869e+02
I0506 12:38:48.853089 140299910223616 run_lib.py:145] step: 24300, training_loss: 6.00063e+01
I0506 12:38:48.907485 140299910223616 run_lib.py:158] step: 24300, eval_loss: 1.34852e+02
I0506 12:38:55.865911 140299910223616 run_lib.py:145] step: 24350, training_loss: 1.52282e+02
I0506 12:39:02.539905 140299910223616 run_lib.py:145] step: 24400, training_loss: 1.67515e+02
I0506 12:39:02.590991 140299910223616 run_lib.py:158] step: 24400, eval_loss: 1.76568e+02
I0506 12:39:09.427475 140299910223616 run_lib.py:145] step: 24450, training_loss: 1.40712e+02
I0506 12:39:16.078680 140299910223616 run_lib.py:145] step: 24500, training_loss: 1.22350e+02
I0506 12:39:16.133936 140299910223616 run_lib.py:158] step: 24500, eval_loss: 8.84430e+01
I0506 12:39:23.062928 140299910223616 run_lib.py:145] step: 24550, training_loss: 9.26527e+01
I0506 12:39:29.858619 140299910223616 run_lib.py:145] step: 24600, training_loss: 1.06640e+02
I0506 12:39:29.914602 140299910223616 run_lib.py:158] step: 24600, eval_loss: 1.62280e+02
I0506 12:39:36.440646 140299910223616 run_lib.py:145] step: 24650, training_loss: 1.49741e+02
I0506 12:39:43.350664 140299910223616 run_lib.py:145] step: 24700, training_loss: 1.34858e+02
I0506 12:39:43.408552 140299910223616 run_lib.py:158] step: 24700, eval_loss: 1.73171e+02
I0506 12:39:50.041511 140299910223616 run_lib.py:145] step: 24750, training_loss: 2.12560e+02
I0506 12:39:56.846536 140299910223616 run_lib.py:145] step: 24800, training_loss: 1.44908e+02
I0506 12:39:56.907850 140299910223616 run_lib.py:158] step: 24800, eval_loss: 1.69084e+02
I0506 12:40:03.546000 140299910223616 run_lib.py:145] step: 24850, training_loss: 1.56176e+02
I0506 12:40:10.614847 140299910223616 run_lib.py:145] step: 24900, training_loss: 1.50925e+02
I0506 12:40:10.675619 140299910223616 run_lib.py:158] step: 24900, eval_loss: 9.93018e+01
I0506 12:40:17.424335 140299910223616 run_lib.py:145] step: 24950, training_loss: 1.18713e+02
I0506 12:40:24.036613 140299910223616 run_lib.py:145] step: 25000, training_loss: 9.64829e+01
I0506 12:40:24.091412 140299910223616 run_lib.py:158] step: 25000, eval_loss: 9.69706e+01
I0506 12:40:31.128478 140299910223616 run_lib.py:145] step: 25050, training_loss: 1.12455e+02
I0506 12:40:37.740819 140299910223616 run_lib.py:145] step: 25100, training_loss: 1.65446e+02
I0506 12:40:37.793839 140299910223616 run_lib.py:158] step: 25100, eval_loss: 1.47536e+02
I0506 12:40:44.455471 140299910223616 run_lib.py:145] step: 25150, training_loss: 1.45122e+02
I0506 12:40:51.091208 140299910223616 run_lib.py:145] step: 25200, training_loss: 1.56058e+02
I0506 12:40:51.149645 140299910223616 run_lib.py:158] step: 25200, eval_loss: 1.71366e+02
I0506 12:40:58.179190 140299910223616 run_lib.py:145] step: 25250, training_loss: 1.64288e+02
I0506 12:41:04.794173 140299910223616 run_lib.py:145] step: 25300, training_loss: 2.35676e+02
I0506 12:41:04.849827 140299910223616 run_lib.py:158] step: 25300, eval_loss: 7.24514e+01
I0506 12:41:11.645600 140299910223616 run_lib.py:145] step: 25350, training_loss: 1.61663e+02
I0506 12:41:18.420091 140299910223616 run_lib.py:145] step: 25400, training_loss: 1.12481e+02
I0506 12:41:18.478550 140299910223616 run_lib.py:158] step: 25400, eval_loss: 1.93612e+02
I0506 12:41:25.178950 140299910223616 run_lib.py:145] step: 25450, training_loss: 1.04448e+02
I0506 12:41:31.667331 140299910223616 run_lib.py:145] step: 25500, training_loss: 1.94063e+02
I0506 12:41:31.723038 140299910223616 run_lib.py:158] step: 25500, eval_loss: 1.82789e+02
I0506 12:41:38.467755 140299910223616 run_lib.py:145] step: 25550, training_loss: 1.68062e+02
I0506 12:41:45.516498 140299910223616 run_lib.py:145] step: 25600, training_loss: 1.21447e+02
I0506 12:41:45.571815 140299910223616 run_lib.py:158] step: 25600, eval_loss: 1.38106e+02
I0506 12:41:52.261775 140299910223616 run_lib.py:145] step: 25650, training_loss: 1.29295e+02
I0506 12:41:58.933652 140299910223616 run_lib.py:145] step: 25700, training_loss: 9.32140e+01
I0506 12:41:58.992708 140299910223616 run_lib.py:158] step: 25700, eval_loss: 1.54267e+02
I0506 12:42:05.769200 140299910223616 run_lib.py:145] step: 25750, training_loss: 1.33264e+02
I0506 12:42:12.594380 140299910223616 run_lib.py:145] step: 25800, training_loss: 9.05062e+01
I0506 12:42:12.656548 140299910223616 run_lib.py:158] step: 25800, eval_loss: 1.04547e+02
I0506 12:42:19.353457 140299910223616 run_lib.py:145] step: 25850, training_loss: 1.08672e+02
I0506 12:42:26.028669 140299910223616 run_lib.py:145] step: 25900, training_loss: 1.07310e+02
I0506 12:42:26.084192 140299910223616 run_lib.py:158] step: 25900, eval_loss: 1.01652e+02
I0506 12:42:33.099283 140299910223616 run_lib.py:145] step: 25950, training_loss: 1.50989e+02
I0506 12:42:39.607209 140299910223616 run_lib.py:145] step: 26000, training_loss: 1.38548e+02
I0506 12:42:39.664532 140299910223616 run_lib.py:158] step: 26000, eval_loss: 1.48104e+02
I0506 12:42:46.411505 140299910223616 run_lib.py:145] step: 26050, training_loss: 1.41948e+02
I0506 12:42:53.315853 140299910223616 run_lib.py:145] step: 26100, training_loss: 1.33707e+02
I0506 12:42:53.374675 140299910223616 run_lib.py:158] step: 26100, eval_loss: 1.66115e+02
I0506 12:43:00.079215 140299910223616 run_lib.py:145] step: 26150, training_loss: 1.39256e+02
I0506 12:43:06.617166 140299910223616 run_lib.py:145] step: 26200, training_loss: 1.74917e+02
I0506 12:43:06.671100 140299910223616 run_lib.py:158] step: 26200, eval_loss: 1.38716e+02
I0506 12:43:13.492223 140299910223616 run_lib.py:145] step: 26250, training_loss: 7.77656e+01
I0506 12:43:20.759599 140299910223616 run_lib.py:145] step: 26300, training_loss: 1.27771e+02
I0506 12:43:20.818604 140299910223616 run_lib.py:158] step: 26300, eval_loss: 1.51093e+02
I0506 12:43:27.401894 140299910223616 run_lib.py:145] step: 26350, training_loss: 1.42002e+02
I0506 12:43:34.161251 140299910223616 run_lib.py:145] step: 26400, training_loss: 1.29304e+02
I0506 12:43:34.222223 140299910223616 run_lib.py:158] step: 26400, eval_loss: 1.68501e+02
I0506 12:43:41.165722 140299910223616 run_lib.py:145] step: 26450, training_loss: 6.30016e+01
I0506 12:43:47.888792 140299910223616 run_lib.py:145] step: 26500, training_loss: 2.25550e+02
I0506 12:43:47.948467 140299910223616 run_lib.py:158] step: 26500, eval_loss: 1.43364e+02
I0506 12:43:54.501575 140299910223616 run_lib.py:145] step: 26550, training_loss: 9.30658e+01
I0506 12:44:01.309089 140299910223616 run_lib.py:145] step: 26600, training_loss: 1.53563e+02
I0506 12:44:01.369285 140299910223616 run_lib.py:158] step: 26600, eval_loss: 1.39167e+02
I0506 12:44:08.418206 140299910223616 run_lib.py:145] step: 26650, training_loss: 1.50644e+02
I0506 12:44:15.002180 140299910223616 run_lib.py:145] step: 26700, training_loss: 1.93343e+02
I0506 12:44:15.063443 140299910223616 run_lib.py:158] step: 26700, eval_loss: 1.82277e+02
I0506 12:44:21.846278 140299910223616 run_lib.py:145] step: 26750, training_loss: 1.52371e+02
I0506 12:44:28.809654 140299910223616 run_lib.py:145] step: 26800, training_loss: 1.80698e+02
I0506 12:44:28.869490 140299910223616 run_lib.py:158] step: 26800, eval_loss: 1.43150e+02
I0506 12:44:35.476432 140299910223616 run_lib.py:145] step: 26850, training_loss: 1.65685e+02
I0506 12:44:42.284845 140299910223616 run_lib.py:145] step: 26900, training_loss: 1.73179e+02
I0506 12:44:42.349465 140299910223616 run_lib.py:158] step: 26900, eval_loss: 1.73452e+02
I0506 12:44:48.977186 140299910223616 run_lib.py:145] step: 26950, training_loss: 1.44096e+02
I0506 12:44:55.878713 140299910223616 run_lib.py:145] step: 27000, training_loss: 1.51440e+02
I0506 12:44:55.935332 140299910223616 run_lib.py:158] step: 27000, eval_loss: 1.36488e+02
I0506 12:45:02.755859 140299910223616 run_lib.py:145] step: 27050, training_loss: 1.36020e+02
I0506 12:45:09.564670 140299910223616 run_lib.py:145] step: 27100, training_loss: 1.17446e+02
I0506 12:45:09.620031 140299910223616 run_lib.py:158] step: 27100, eval_loss: 1.53887e+02
I0506 12:45:16.337113 140299910223616 run_lib.py:145] step: 27150, training_loss: 1.46184e+02
I0506 12:45:23.041848 140299910223616 run_lib.py:145] step: 27200, training_loss: 1.54922e+02
I0506 12:45:23.098284 140299910223616 run_lib.py:158] step: 27200, eval_loss: 1.28599e+02
I0506 12:45:29.771712 140299910223616 run_lib.py:145] step: 27250, training_loss: 1.11187e+02
I0506 12:45:36.426179 140299910223616 run_lib.py:145] step: 27300, training_loss: 9.64890e+01
I0506 12:45:36.487279 140299910223616 run_lib.py:158] step: 27300, eval_loss: 1.16820e+02
I0506 12:45:43.333833 140299910223616 run_lib.py:145] step: 27350, training_loss: 1.43574e+02
I0506 12:45:50.153385 140299910223616 run_lib.py:145] step: 27400, training_loss: 2.01729e+02
I0506 12:45:50.212694 140299910223616 run_lib.py:158] step: 27400, eval_loss: 1.97806e+02
I0506 12:45:56.774650 140299910223616 run_lib.py:145] step: 27450, training_loss: 1.31361e+02
I0506 12:46:03.864122 140299910223616 run_lib.py:145] step: 27500, training_loss: 9.63180e+01
I0506 12:46:03.923416 140299910223616 run_lib.py:158] step: 27500, eval_loss: 1.76613e+02
I0506 12:46:10.706661 140299910223616 run_lib.py:145] step: 27550, training_loss: 1.11876e+02
I0506 12:46:17.439952 140299910223616 run_lib.py:145] step: 27600, training_loss: 1.48073e+02
I0506 12:46:17.491226 140299910223616 run_lib.py:158] step: 27600, eval_loss: 1.21160e+02
I0506 12:46:24.166143 140299910223616 run_lib.py:145] step: 27650, training_loss: 1.27426e+02
I0506 12:46:31.157579 140299910223616 run_lib.py:145] step: 27700, training_loss: 2.01788e+02
I0506 12:46:31.219063 140299910223616 run_lib.py:158] step: 27700, eval_loss: 9.30662e+01
I0506 12:46:37.799052 140299910223616 run_lib.py:145] step: 27750, training_loss: 1.78567e+02
I0506 12:46:44.546785 140299910223616 run_lib.py:145] step: 27800, training_loss: 1.59183e+02
I0506 12:46:44.606305 140299910223616 run_lib.py:158] step: 27800, eval_loss: 1.42076e+02
I0506 12:46:51.627555 140299910223616 run_lib.py:145] step: 27850, training_loss: 1.53922e+02
I0506 12:46:58.217687 140299910223616 run_lib.py:145] step: 27900, training_loss: 2.01958e+02
I0506 12:46:58.275966 140299910223616 run_lib.py:158] step: 27900, eval_loss: 2.22457e+02
I0506 12:47:04.903158 140299910223616 run_lib.py:145] step: 27950, training_loss: 1.43409e+02
I0506 12:47:11.885948 140299910223616 run_lib.py:145] step: 28000, training_loss: 1.34386e+02
I0506 12:47:11.942735 140299910223616 run_lib.py:158] step: 28000, eval_loss: 2.00614e+02
I0506 12:47:18.488713 140299910223616 run_lib.py:145] step: 28050, training_loss: 1.01652e+02
I0506 12:47:25.354174 140299910223616 run_lib.py:145] step: 28100, training_loss: 1.37873e+02
I0506 12:47:25.412037 140299910223616 run_lib.py:158] step: 28100, eval_loss: 1.45306e+02
I0506 12:47:32.098846 140299910223616 run_lib.py:145] step: 28150, training_loss: 1.87492e+02
I0506 12:47:39.118695 140299910223616 run_lib.py:145] step: 28200, training_loss: 9.11402e+01
I0506 12:47:39.176296 140299910223616 run_lib.py:158] step: 28200, eval_loss: 1.27094e+02
I0506 12:47:45.728239 140299910223616 run_lib.py:145] step: 28250, training_loss: 2.24959e+02
I0506 12:47:52.442294 140299910223616 run_lib.py:145] step: 28300, training_loss: 2.02266e+02
I0506 12:47:52.503214 140299910223616 run_lib.py:158] step: 28300, eval_loss: 1.67175e+02
I0506 12:47:59.352305 140299910223616 run_lib.py:145] step: 28350, training_loss: 1.50140e+02
I0506 12:48:06.041747 140299910223616 run_lib.py:145] step: 28400, training_loss: 1.51408e+02
I0506 12:48:06.096290 140299910223616 run_lib.py:158] step: 28400, eval_loss: 1.15040e+02
I0506 12:48:12.766311 140299910223616 run_lib.py:145] step: 28450, training_loss: 2.02517e+02
I0506 12:48:19.645103 140299910223616 run_lib.py:145] step: 28500, training_loss: 1.33663e+02
I0506 12:48:19.698330 140299910223616 run_lib.py:158] step: 28500, eval_loss: 7.04755e+01
I0506 12:48:26.526298 140299910223616 run_lib.py:145] step: 28550, training_loss: 1.59788e+02
I0506 12:48:33.235605 140299910223616 run_lib.py:145] step: 28600, training_loss: 1.73940e+02
I0506 12:48:33.287789 140299910223616 run_lib.py:158] step: 28600, eval_loss: 1.31014e+02
I0506 12:48:40.072086 140299910223616 run_lib.py:145] step: 28650, training_loss: 1.89332e+02
I0506 12:48:46.933818 140299910223616 run_lib.py:145] step: 28700, training_loss: 7.43522e+01
I0506 12:48:46.994745 140299910223616 run_lib.py:158] step: 28700, eval_loss: 2.39704e+02
I0506 12:48:53.845318 140299910223616 run_lib.py:145] step: 28750, training_loss: 1.39492e+02
I0506 12:49:00.362758 140299910223616 run_lib.py:145] step: 28800, training_loss: 1.13119e+02
I0506 12:49:00.418439 140299910223616 run_lib.py:158] step: 28800, eval_loss: 1.73341e+02
I0506 12:49:07.181884 140299910223616 run_lib.py:145] step: 28850, training_loss: 1.65193e+02
I0506 12:49:14.151289 140299910223616 run_lib.py:145] step: 28900, training_loss: 9.66431e+01
I0506 12:49:14.205384 140299910223616 run_lib.py:158] step: 28900, eval_loss: 1.42528e+02
I0506 12:49:21.090055 140299910223616 run_lib.py:145] step: 28950, training_loss: 1.73250e+02
I0506 12:49:27.889088 140299910223616 run_lib.py:145] step: 29000, training_loss: 1.51340e+02
I0506 12:49:27.942401 140299910223616 run_lib.py:158] step: 29000, eval_loss: 1.39835e+02
I0506 12:49:34.769893 140299910223616 run_lib.py:145] step: 29050, training_loss: 1.42935e+02
I0506 12:49:41.638142 140299910223616 run_lib.py:145] step: 29100, training_loss: 1.80172e+02
I0506 12:49:41.697705 140299910223616 run_lib.py:158] step: 29100, eval_loss: 1.20579e+02
I0506 12:49:48.293064 140299910223616 run_lib.py:145] step: 29150, training_loss: 1.20038e+02
I0506 12:49:55.186095 140299910223616 run_lib.py:145] step: 29200, training_loss: 1.40462e+02
I0506 12:49:55.243569 140299910223616 run_lib.py:158] step: 29200, eval_loss: 1.26911e+02
I0506 12:50:02.362745 140299910223616 run_lib.py:145] step: 29250, training_loss: 9.94962e+01
I0506 12:50:08.966456 140299910223616 run_lib.py:145] step: 29300, training_loss: 1.12717e+02
I0506 12:50:09.019624 140299910223616 run_lib.py:158] step: 29300, eval_loss: 1.29875e+02
I0506 12:50:15.751353 140299910223616 run_lib.py:145] step: 29350, training_loss: 1.78787e+02
I0506 12:50:22.566538 140299910223616 run_lib.py:145] step: 29400, training_loss: 1.61729e+02
I0506 12:50:22.627438 140299910223616 run_lib.py:158] step: 29400, eval_loss: 1.88713e+02
I0506 12:50:29.554709 140299910223616 run_lib.py:145] step: 29450, training_loss: 1.58515e+02
I0506 12:50:36.139635 140299910223616 run_lib.py:145] step: 29500, training_loss: 1.17222e+02
I0506 12:50:36.198554 140299910223616 run_lib.py:158] step: 29500, eval_loss: 1.77797e+02
I0506 12:50:42.951565 140299910223616 run_lib.py:145] step: 29550, training_loss: 1.32622e+02
I0506 12:50:49.865977 140299910223616 run_lib.py:145] step: 29600, training_loss: 1.46835e+02
I0506 12:50:49.924221 140299910223616 run_lib.py:158] step: 29600, eval_loss: 1.26668e+02
I0506 12:50:56.519204 140299910223616 run_lib.py:145] step: 29650, training_loss: 1.07553e+02
I0506 12:51:03.039541 140299910223616 run_lib.py:145] step: 29700, training_loss: 1.64149e+02
I0506 12:51:03.091304 140299910223616 run_lib.py:158] step: 29700, eval_loss: 1.67301e+02
I0506 12:51:10.178441 140299910223616 run_lib.py:145] step: 29750, training_loss: 1.19274e+02
I0506 12:51:16.914728 140299910223616 run_lib.py:145] step: 29800, training_loss: 8.96389e+01
I0506 12:51:16.968861 140299910223616 run_lib.py:158] step: 29800, eval_loss: 1.76338e+02
I0506 12:51:23.652601 140299910223616 run_lib.py:145] step: 29850, training_loss: 1.62927e+02
I0506 12:51:30.511443 140299910223616 run_lib.py:145] step: 29900, training_loss: 1.53992e+02
I0506 12:51:30.567075 140299910223616 run_lib.py:158] step: 29900, eval_loss: 1.21577e+02
I0506 12:51:37.406296 140299910223616 run_lib.py:145] step: 29950, training_loss: 1.44978e+02
I0506 12:51:44.130360 140299910223616 run_lib.py:145] step: 30000, training_loss: 1.73113e+02
I0506 12:51:44.337481 140299910223616 run_lib.py:158] step: 30000, eval_loss: 1.00186e+02
I0506 12:51:50.941502 140299910223616 run_lib.py:145] step: 30050, training_loss: 8.34903e+01
I0506 12:51:57.932518 140299910223616 run_lib.py:145] step: 30100, training_loss: 1.90267e+02
I0506 12:51:57.996648 140299910223616 run_lib.py:158] step: 30100, eval_loss: 8.36422e+01
I0506 12:52:04.939579 140299910223616 run_lib.py:145] step: 30150, training_loss: 1.24372e+02
I0506 12:52:11.428825 140299910223616 run_lib.py:145] step: 30200, training_loss: 1.79947e+02
I0506 12:52:11.486607 140299910223616 run_lib.py:158] step: 30200, eval_loss: 1.35283e+02
I0506 12:52:18.395322 140299910223616 run_lib.py:145] step: 30250, training_loss: 1.01277e+02
I0506 12:52:25.288941 140299910223616 run_lib.py:145] step: 30300, training_loss: 1.87870e+02
I0506 12:52:25.346324 140299910223616 run_lib.py:158] step: 30300, eval_loss: 1.61107e+02
I0506 12:52:32.070982 140299910223616 run_lib.py:145] step: 30350, training_loss: 1.73333e+02
I0506 12:52:38.899512 140299910223616 run_lib.py:145] step: 30400, training_loss: 2.05004e+02
I0506 12:52:38.956517 140299910223616 run_lib.py:158] step: 30400, eval_loss: 1.22248e+02
I0506 12:52:45.864802 140299910223616 run_lib.py:145] step: 30450, training_loss: 1.70594e+02
I0506 12:52:52.581410 140299910223616 run_lib.py:145] step: 30500, training_loss: 2.03864e+02
I0506 12:52:52.640577 140299910223616 run_lib.py:158] step: 30500, eval_loss: 1.50502e+02
I0506 12:52:59.565788 140299910223616 run_lib.py:145] step: 30550, training_loss: 1.13101e+02
I0506 12:53:06.218759 140299910223616 run_lib.py:145] step: 30600, training_loss: 1.07891e+02
I0506 12:53:06.276280 140299910223616 run_lib.py:158] step: 30600, eval_loss: 1.37849e+02
I0506 12:53:13.210217 140299910223616 run_lib.py:145] step: 30650, training_loss: 1.63195e+02
I0506 12:53:19.879529 140299910223616 run_lib.py:145] step: 30700, training_loss: 1.77931e+02
I0506 12:53:19.938552 140299910223616 run_lib.py:158] step: 30700, eval_loss: 8.58870e+01
I0506 12:53:26.854290 140299910223616 run_lib.py:145] step: 30750, training_loss: 1.45908e+02
I0506 12:53:33.830496 140299910223616 run_lib.py:145] step: 30800, training_loss: 1.07475e+02
I0506 12:53:33.882163 140299910223616 run_lib.py:158] step: 30800, eval_loss: 1.83727e+02
I0506 12:53:40.468777 140299910223616 run_lib.py:145] step: 30850, training_loss: 1.08750e+02
I0506 12:53:47.210685 140299910223616 run_lib.py:145] step: 30900, training_loss: 1.21062e+02
I0506 12:53:47.264491 140299910223616 run_lib.py:158] step: 30900, eval_loss: 1.94199e+02
I0506 12:53:54.013998 140299910223616 run_lib.py:145] step: 30950, training_loss: 1.21611e+02
I0506 12:54:00.896520 140299910223616 run_lib.py:145] step: 31000, training_loss: 1.21700e+02
I0506 12:54:00.960305 140299910223616 run_lib.py:158] step: 31000, eval_loss: 1.66335e+02
I0506 12:54:07.681746 140299910223616 run_lib.py:145] step: 31050, training_loss: 1.03345e+02
I0506 12:54:14.342930 140299910223616 run_lib.py:145] step: 31100, training_loss: 1.80546e+02
I0506 12:54:14.400691 140299910223616 run_lib.py:158] step: 31100, eval_loss: 1.41369e+02
I0506 12:54:21.383489 140299910223616 run_lib.py:145] step: 31150, training_loss: 1.45667e+02
I0506 12:54:28.210736 140299910223616 run_lib.py:145] step: 31200, training_loss: 1.79492e+02
I0506 12:54:28.274745 140299910223616 run_lib.py:158] step: 31200, eval_loss: 1.10226e+02
I0506 12:54:35.036492 140299910223616 run_lib.py:145] step: 31250, training_loss: 1.68564e+02
I0506 12:54:41.545989 140299910223616 run_lib.py:145] step: 31300, training_loss: 1.36279e+02
I0506 12:54:41.610460 140299910223616 run_lib.py:158] step: 31300, eval_loss: 1.72264e+02
I0506 12:54:48.478741 140299910223616 run_lib.py:145] step: 31350, training_loss: 2.07228e+02
I0506 12:54:55.180437 140299910223616 run_lib.py:145] step: 31400, training_loss: 1.55896e+02
I0506 12:54:55.234810 140299910223616 run_lib.py:158] step: 31400, eval_loss: 1.59031e+02
I0506 12:55:01.895955 140299910223616 run_lib.py:145] step: 31450, training_loss: 1.23037e+02
I0506 12:55:09.039855 140299910223616 run_lib.py:145] step: 31500, training_loss: 7.39706e+01
I0506 12:55:09.095818 140299910223616 run_lib.py:158] step: 31500, eval_loss: 1.12568e+02
I0506 12:55:15.835041 140299910223616 run_lib.py:145] step: 31550, training_loss: 1.87309e+02
I0506 12:55:22.443823 140299910223616 run_lib.py:145] step: 31600, training_loss: 1.29138e+02
I0506 12:55:22.496315 140299910223616 run_lib.py:158] step: 31600, eval_loss: 9.01024e+01
I0506 12:55:29.220475 140299910223616 run_lib.py:145] step: 31650, training_loss: 1.49749e+02
I0506 12:55:36.072718 140299910223616 run_lib.py:145] step: 31700, training_loss: 1.38984e+02
I0506 12:55:36.136157 140299910223616 run_lib.py:158] step: 31700, eval_loss: 1.69645e+02
I0506 12:55:42.887522 140299910223616 run_lib.py:145] step: 31750, training_loss: 1.67235e+02
I0506 12:55:49.735479 140299910223616 run_lib.py:145] step: 31800, training_loss: 1.33999e+02
I0506 12:55:49.793880 140299910223616 run_lib.py:158] step: 31800, eval_loss: 1.12196e+02
I0506 12:55:56.871169 140299910223616 run_lib.py:145] step: 31850, training_loss: 1.53356e+02
I0506 12:56:03.602529 140299910223616 run_lib.py:145] step: 31900, training_loss: 1.70913e+02
I0506 12:56:03.656012 140299910223616 run_lib.py:158] step: 31900, eval_loss: 1.74834e+02
I0506 12:56:10.206356 140299910223616 run_lib.py:145] step: 31950, training_loss: 1.36997e+02
I0506 12:56:16.918471 140299910223616 run_lib.py:145] step: 32000, training_loss: 9.45647e+01
I0506 12:56:16.972645 140299910223616 run_lib.py:158] step: 32000, eval_loss: 1.58163e+02
I0506 12:56:23.688335 140299910223616 run_lib.py:145] step: 32050, training_loss: 1.46169e+02
I0506 12:56:30.518032 140299910223616 run_lib.py:145] step: 32100, training_loss: 1.09940e+02
I0506 12:56:30.574951 140299910223616 run_lib.py:158] step: 32100, eval_loss: 1.57012e+02
I0506 12:56:37.251960 140299910223616 run_lib.py:145] step: 32150, training_loss: 1.60539e+02
I0506 12:56:44.203438 140299910223616 run_lib.py:145] step: 32200, training_loss: 8.07201e+01
I0506 12:56:44.257632 140299910223616 run_lib.py:158] step: 32200, eval_loss: 1.52668e+02
I0506 12:56:50.805096 140299910223616 run_lib.py:145] step: 32250, training_loss: 1.34174e+02
I0506 12:56:57.671449 140299910223616 run_lib.py:145] step: 32300, training_loss: 1.40942e+02
I0506 12:56:57.732898 140299910223616 run_lib.py:158] step: 32300, eval_loss: 6.76717e+01
I0506 12:57:04.263232 140299910223616 run_lib.py:145] step: 32350, training_loss: 1.56734e+02
I0506 12:57:11.355744 140299910223616 run_lib.py:145] step: 32400, training_loss: 1.10771e+02
I0506 12:57:11.414155 140299910223616 run_lib.py:158] step: 32400, eval_loss: 1.49261e+02
I0506 12:57:18.018508 140299910223616 run_lib.py:145] step: 32450, training_loss: 2.20261e+02
I0506 12:57:24.711547 140299910223616 run_lib.py:145] step: 32500, training_loss: 1.31916e+02
I0506 12:57:24.773156 140299910223616 run_lib.py:158] step: 32500, eval_loss: 2.04113e+02
I0506 12:57:31.674953 140299910223616 run_lib.py:145] step: 32550, training_loss: 1.41354e+02
I0506 12:57:38.325960 140299910223616 run_lib.py:145] step: 32600, training_loss: 2.38293e+02
I0506 12:57:38.375879 140299910223616 run_lib.py:158] step: 32600, eval_loss: 1.60159e+02
I0506 12:57:45.053764 140299910223616 run_lib.py:145] step: 32650, training_loss: 1.95653e+02
I0506 12:57:52.030717 140299910223616 run_lib.py:145] step: 32700, training_loss: 1.22224e+02
I0506 12:57:52.089967 140299910223616 run_lib.py:158] step: 32700, eval_loss: 8.49659e+01
I0506 12:57:58.876066 140299910223616 run_lib.py:145] step: 32750, training_loss: 1.20508e+02
I0506 12:58:05.447159 140299910223616 run_lib.py:145] step: 32800, training_loss: 1.38267e+02
I0506 12:58:05.506296 140299910223616 run_lib.py:158] step: 32800, eval_loss: 7.75649e+01
I0506 12:58:12.345441 140299910223616 run_lib.py:145] step: 32850, training_loss: 1.64683e+02
I0506 12:58:19.175626 140299910223616 run_lib.py:145] step: 32900, training_loss: 1.27788e+02
I0506 12:58:19.225451 140299910223616 run_lib.py:158] step: 32900, eval_loss: 1.44034e+02
I0506 12:58:26.034274 140299910223616 run_lib.py:145] step: 32950, training_loss: 1.41812e+02
I0506 12:58:32.585720 140299910223616 run_lib.py:145] step: 33000, training_loss: 9.79056e+01
I0506 12:58:32.643510 140299910223616 run_lib.py:158] step: 33000, eval_loss: 1.39468e+02
I0506 12:58:39.638738 140299910223616 run_lib.py:145] step: 33050, training_loss: 1.35035e+02
I0506 12:58:46.206144 140299910223616 run_lib.py:145] step: 33100, training_loss: 9.59289e+01
I0506 12:58:46.256521 140299910223616 run_lib.py:158] step: 33100, eval_loss: 1.58072e+02
I0506 12:58:52.722126 140299910223616 run_lib.py:145] step: 33150, training_loss: 1.29050e+02
I0506 12:58:59.503978 140299910223616 run_lib.py:145] step: 33200, training_loss: 1.42467e+02
I0506 12:58:59.567101 140299910223616 run_lib.py:158] step: 33200, eval_loss: 1.23536e+02
I0506 12:59:06.583308 140299910223616 run_lib.py:145] step: 33250, training_loss: 1.55682e+02
I0506 12:59:13.473999 140299910223616 run_lib.py:145] step: 33300, training_loss: 1.70315e+02
I0506 12:59:13.531852 140299910223616 run_lib.py:158] step: 33300, eval_loss: 1.41899e+02
I0506 12:59:20.107049 140299910223616 run_lib.py:145] step: 33350, training_loss: 1.36984e+02
I0506 12:59:27.189112 140299910223616 run_lib.py:145] step: 33400, training_loss: 7.21620e+01
I0506 12:59:27.252300 140299910223616 run_lib.py:158] step: 33400, eval_loss: 1.24660e+02
I0506 12:59:33.741866 140299910223616 run_lib.py:145] step: 33450, training_loss: 1.78533e+02
I0506 12:59:40.494537 140299910223616 run_lib.py:145] step: 33500, training_loss: 1.76553e+02
I0506 12:59:40.556403 140299910223616 run_lib.py:158] step: 33500, eval_loss: 1.83315e+02
I0506 12:59:47.012280 140299910223616 run_lib.py:145] step: 33550, training_loss: 1.48707e+02
I0506 12:59:54.030635 140299910223616 run_lib.py:145] step: 33600, training_loss: 1.27155e+02
I0506 12:59:54.084019 140299910223616 run_lib.py:158] step: 33600, eval_loss: 1.28766e+02
I0506 13:00:00.863595 140299910223616 run_lib.py:145] step: 33650, training_loss: 1.07711e+02
I0506 13:00:07.834515 140299910223616 run_lib.py:145] step: 33700, training_loss: 1.29226e+02
I0506 13:00:07.889568 140299910223616 run_lib.py:158] step: 33700, eval_loss: 1.40312e+02
I0506 13:00:14.833094 140299910223616 run_lib.py:145] step: 33750, training_loss: 1.97551e+02
I0506 13:00:21.621030 140299910223616 run_lib.py:145] step: 33800, training_loss: 9.64554e+01
I0506 13:00:21.679688 140299910223616 run_lib.py:158] step: 33800, eval_loss: 1.48178e+02
I0506 13:00:28.556285 140299910223616 run_lib.py:145] step: 33850, training_loss: 1.49739e+02
I0506 13:00:35.226647 140299910223616 run_lib.py:145] step: 33900, training_loss: 1.67779e+02
I0506 13:00:35.282768 140299910223616 run_lib.py:158] step: 33900, eval_loss: 1.20540e+02
I0506 13:00:42.216759 140299910223616 run_lib.py:145] step: 33950, training_loss: 1.31366e+02
I0506 13:00:48.968537 140299910223616 run_lib.py:145] step: 34000, training_loss: 1.51747e+02
I0506 13:00:49.030247 140299910223616 run_lib.py:158] step: 34000, eval_loss: 1.44954e+02
I0506 13:00:55.699895 140299910223616 run_lib.py:145] step: 34050, training_loss: 1.37330e+02
I0506 13:01:02.726998 140299910223616 run_lib.py:145] step: 34100, training_loss: 1.03490e+02
I0506 13:01:02.783874 140299910223616 run_lib.py:158] step: 34100, eval_loss: 1.60394e+02
I0506 13:01:09.315939 140299910223616 run_lib.py:145] step: 34150, training_loss: 1.75373e+02
I0506 13:01:16.176664 140299910223616 run_lib.py:145] step: 34200, training_loss: 1.22318e+02
I0506 13:01:16.243025 140299910223616 run_lib.py:158] step: 34200, eval_loss: 8.74021e+01
I0506 13:01:22.919000 140299910223616 run_lib.py:145] step: 34250, training_loss: 1.40078e+02
I0506 13:01:29.753041 140299910223616 run_lib.py:145] step: 34300, training_loss: 8.94090e+01
I0506 13:01:29.806997 140299910223616 run_lib.py:158] step: 34300, eval_loss: 1.39423e+02
I0506 13:01:36.564591 140299910223616 run_lib.py:145] step: 34350, training_loss: 1.21083e+02
I0506 13:01:43.336576 140299910223616 run_lib.py:145] step: 34400, training_loss: 1.74263e+02
I0506 13:01:43.398082 140299910223616 run_lib.py:158] step: 34400, eval_loss: 1.94020e+02
I0506 13:01:50.321418 140299910223616 run_lib.py:145] step: 34450, training_loss: 1.58944e+02
I0506 13:01:57.310139 140299910223616 run_lib.py:145] step: 34500, training_loss: 8.61947e+01
I0506 13:01:57.372783 140299910223616 run_lib.py:158] step: 34500, eval_loss: 1.72426e+02
I0506 13:02:03.944464 140299910223616 run_lib.py:145] step: 34550, training_loss: 1.42901e+02
I0506 13:02:10.729398 140299910223616 run_lib.py:145] step: 34600, training_loss: 1.33683e+02
I0506 13:02:10.783999 140299910223616 run_lib.py:158] step: 34600, eval_loss: 1.14993e+02
I0506 13:02:17.831190 140299910223616 run_lib.py:145] step: 34650, training_loss: 1.21687e+02
I0506 13:02:24.343567 140299910223616 run_lib.py:145] step: 34700, training_loss: 1.35634e+02
I0506 13:02:24.399450 140299910223616 run_lib.py:158] step: 34700, eval_loss: 1.21997e+02
I0506 13:02:31.244502 140299910223616 run_lib.py:145] step: 34750, training_loss: 1.80490e+02
I0506 13:02:38.099127 140299910223616 run_lib.py:145] step: 34800, training_loss: 1.20215e+02
I0506 13:02:38.158762 140299910223616 run_lib.py:158] step: 34800, eval_loss: 1.04147e+02
I0506 13:02:44.872648 140299910223616 run_lib.py:145] step: 34850, training_loss: 1.65991e+02
I0506 13:02:51.313404 140299910223616 run_lib.py:145] step: 34900, training_loss: 2.04481e+02
I0506 13:02:51.372323 140299910223616 run_lib.py:158] step: 34900, eval_loss: 1.64984e+02
I0506 13:02:58.178795 140299910223616 run_lib.py:145] step: 34950, training_loss: 1.04118e+02
I0506 13:03:05.136496 140299910223616 run_lib.py:145] step: 35000, training_loss: 1.49938e+02
I0506 13:03:05.193257 140299910223616 run_lib.py:158] step: 35000, eval_loss: 2.03585e+02
I0506 13:03:11.914654 140299910223616 run_lib.py:145] step: 35050, training_loss: 9.30456e+01
I0506 13:03:18.529731 140299910223616 run_lib.py:145] step: 35100, training_loss: 2.30655e+02
I0506 13:03:18.586720 140299910223616 run_lib.py:158] step: 35100, eval_loss: 1.26768e+02
I0506 13:03:25.606770 140299910223616 run_lib.py:145] step: 35150, training_loss: 1.64496e+02
I0506 13:03:32.433960 140299910223616 run_lib.py:145] step: 35200, training_loss: 1.33695e+02
I0506 13:03:32.494670 140299910223616 run_lib.py:158] step: 35200, eval_loss: 1.42993e+02
I0506 13:03:39.148320 140299910223616 run_lib.py:145] step: 35250, training_loss: 1.23158e+02
I0506 13:03:45.812988 140299910223616 run_lib.py:145] step: 35300, training_loss: 1.72611e+02
I0506 13:03:45.867772 140299910223616 run_lib.py:158] step: 35300, eval_loss: 1.92938e+02
I0506 13:03:52.785156 140299910223616 run_lib.py:145] step: 35350, training_loss: 1.39038e+02
I0506 13:03:59.349475 140299910223616 run_lib.py:145] step: 35400, training_loss: 1.35246e+02
I0506 13:03:59.404335 140299910223616 run_lib.py:158] step: 35400, eval_loss: 1.08298e+02
I0506 13:04:06.255782 140299910223616 run_lib.py:145] step: 35450, training_loss: 1.43954e+02
I0506 13:04:13.334869 140299910223616 run_lib.py:145] step: 35500, training_loss: 1.01754e+02
I0506 13:04:13.389874 140299910223616 run_lib.py:158] step: 35500, eval_loss: 1.35394e+02
I0506 13:04:20.106356 140299910223616 run_lib.py:145] step: 35550, training_loss: 2.01668e+02
I0506 13:04:26.837748 140299910223616 run_lib.py:145] step: 35600, training_loss: 9.39546e+01
I0506 13:04:26.893659 140299910223616 run_lib.py:158] step: 35600, eval_loss: 1.83207e+02
I0506 13:04:33.789766 140299910223616 run_lib.py:145] step: 35650, training_loss: 1.31612e+02
I0506 13:04:40.657370 140299910223616 run_lib.py:145] step: 35700, training_loss: 1.40629e+02
I0506 13:04:40.713681 140299910223616 run_lib.py:158] step: 35700, eval_loss: 1.45287e+02
I0506 13:04:47.480024 140299910223616 run_lib.py:145] step: 35750, training_loss: 1.15309e+02
I0506 13:04:54.170773 140299910223616 run_lib.py:145] step: 35800, training_loss: 1.54371e+02
I0506 13:04:54.225467 140299910223616 run_lib.py:158] step: 35800, eval_loss: 7.67120e+01
I0506 13:05:01.338979 140299910223616 run_lib.py:145] step: 35850, training_loss: 1.24811e+02
I0506 13:05:07.891383 140299910223616 run_lib.py:145] step: 35900, training_loss: 1.58869e+02
I0506 13:05:07.946214 140299910223616 run_lib.py:158] step: 35900, eval_loss: 1.44593e+02
I0506 13:05:14.741920 140299910223616 run_lib.py:145] step: 35950, training_loss: 1.14927e+02
I0506 13:05:21.291868 140299910223616 run_lib.py:145] step: 36000, training_loss: 1.31796e+02
I0506 13:05:21.347994 140299910223616 run_lib.py:158] step: 36000, eval_loss: 1.28636e+02
I0506 13:05:28.236524 140299910223616 run_lib.py:145] step: 36050, training_loss: 1.39782e+02
I0506 13:05:35.023936 140299910223616 run_lib.py:145] step: 36100, training_loss: 1.41251e+02
I0506 13:05:35.074753 140299910223616 run_lib.py:158] step: 36100, eval_loss: 1.31454e+02
I0506 13:05:41.845985 140299910223616 run_lib.py:145] step: 36150, training_loss: 1.69436e+02
I0506 13:05:48.714339 140299910223616 run_lib.py:145] step: 36200, training_loss: 7.95103e+01
I0506 13:05:48.771715 140299910223616 run_lib.py:158] step: 36200, eval_loss: 1.73252e+02
I0506 13:05:55.585890 140299910223616 run_lib.py:145] step: 36250, training_loss: 1.41010e+02
I0506 13:06:02.460830 140299910223616 run_lib.py:145] step: 36300, training_loss: 1.63454e+02
I0506 13:06:02.524338 140299910223616 run_lib.py:158] step: 36300, eval_loss: 1.08932e+02
I0506 13:06:09.369560 140299910223616 run_lib.py:145] step: 36350, training_loss: 1.15838e+02
I0506 13:06:16.497912 140299910223616 run_lib.py:145] step: 36400, training_loss: 1.12199e+02
I0506 13:06:16.555042 140299910223616 run_lib.py:158] step: 36400, eval_loss: 1.32252e+02
I0506 13:06:23.397732 140299910223616 run_lib.py:145] step: 36450, training_loss: 1.59587e+02
I0506 13:06:30.066782 140299910223616 run_lib.py:145] step: 36500, training_loss: 1.60256e+02
I0506 13:06:30.123341 140299910223616 run_lib.py:158] step: 36500, eval_loss: 1.34098e+02
I0506 13:06:37.027879 140299910223616 run_lib.py:145] step: 36550, training_loss: 1.12433e+02
I0506 13:06:43.728557 140299910223616 run_lib.py:145] step: 36600, training_loss: 1.47568e+02
I0506 13:06:43.779461 140299910223616 run_lib.py:158] step: 36600, eval_loss: 1.20564e+02
I0506 13:06:50.604262 140299910223616 run_lib.py:145] step: 36650, training_loss: 1.04960e+02
I0506 13:06:57.222589 140299910223616 run_lib.py:145] step: 36700, training_loss: 2.19131e+02
I0506 13:06:57.274729 140299910223616 run_lib.py:158] step: 36700, eval_loss: 7.38250e+01
I0506 13:07:04.331753 140299910223616 run_lib.py:145] step: 36750, training_loss: 2.30502e+02
I0506 13:07:10.831752 140299910223616 run_lib.py:145] step: 36800, training_loss: 1.04809e+02
I0506 13:07:10.891345 140299910223616 run_lib.py:158] step: 36800, eval_loss: 1.25437e+02
I0506 13:07:17.755658 140299910223616 run_lib.py:145] step: 36850, training_loss: 2.28260e+02
I0506 13:07:24.789024 140299910223616 run_lib.py:145] step: 36900, training_loss: 1.89027e+02
I0506 13:07:24.842556 140299910223616 run_lib.py:158] step: 36900, eval_loss: 1.30298e+02
I0506 13:07:31.507078 140299910223616 run_lib.py:145] step: 36950, training_loss: 1.22385e+02
I0506 13:07:38.081060 140299910223616 run_lib.py:145] step: 37000, training_loss: 7.14949e+01
I0506 13:07:38.141873 140299910223616 run_lib.py:158] step: 37000, eval_loss: 8.74348e+01
I0506 13:07:44.878561 140299910223616 run_lib.py:145] step: 37050, training_loss: 1.41710e+02
I0506 13:07:51.940382 140299910223616 run_lib.py:145] step: 37100, training_loss: 1.87917e+02
I0506 13:07:51.999986 140299910223616 run_lib.py:158] step: 37100, eval_loss: 1.80422e+02
I0506 13:07:58.580272 140299910223616 run_lib.py:145] step: 37150, training_loss: 1.54547e+02
I0506 13:08:05.517920 140299910223616 run_lib.py:145] step: 37200, training_loss: 1.39922e+02
I0506 13:08:05.578520 140299910223616 run_lib.py:158] step: 37200, eval_loss: 1.09996e+02
I0506 13:08:12.441093 140299910223616 run_lib.py:145] step: 37250, training_loss: 1.18932e+02
I0506 13:08:19.152874 140299910223616 run_lib.py:145] step: 37300, training_loss: 9.53443e+01
I0506 13:08:19.209020 140299910223616 run_lib.py:158] step: 37300, eval_loss: 1.43675e+02
I0506 13:08:25.857789 140299910223616 run_lib.py:145] step: 37350, training_loss: 1.12031e+02
I0506 13:08:32.869261 140299910223616 run_lib.py:145] step: 37400, training_loss: 1.17989e+02
I0506 13:08:32.926515 140299910223616 run_lib.py:158] step: 37400, eval_loss: 1.40231e+02
I0506 13:08:39.709785 140299910223616 run_lib.py:145] step: 37450, training_loss: 1.43097e+02
I0506 13:08:46.567468 140299910223616 run_lib.py:145] step: 37500, training_loss: 1.17150e+02
I0506 13:08:46.625730 140299910223616 run_lib.py:158] step: 37500, eval_loss: 1.22721e+02
I0506 13:08:53.459169 140299910223616 run_lib.py:145] step: 37550, training_loss: 1.35803e+02
I0506 13:09:00.305521 140299910223616 run_lib.py:145] step: 37600, training_loss: 8.75790e+01
I0506 13:09:00.360820 140299910223616 run_lib.py:158] step: 37600, eval_loss: 1.00094e+02
I0506 13:09:07.103763 140299910223616 run_lib.py:145] step: 37650, training_loss: 1.34080e+02
I0506 13:09:13.892716 140299910223616 run_lib.py:145] step: 37700, training_loss: 2.53777e+02
I0506 13:09:13.946814 140299910223616 run_lib.py:158] step: 37700, eval_loss: 1.57862e+02
I0506 13:09:20.966406 140299910223616 run_lib.py:145] step: 37750, training_loss: 1.35165e+02
I0506 13:09:27.672238 140299910223616 run_lib.py:145] step: 37800, training_loss: 1.24187e+02
I0506 13:09:27.729866 140299910223616 run_lib.py:158] step: 37800, eval_loss: 8.34588e+01
I0506 13:09:34.323243 140299910223616 run_lib.py:145] step: 37850, training_loss: 8.02387e+01
I0506 13:09:41.115960 140299910223616 run_lib.py:145] step: 37900, training_loss: 1.27784e+02
I0506 13:09:41.171318 140299910223616 run_lib.py:158] step: 37900, eval_loss: 3.75815e+01
I0506 13:09:48.204315 140299910223616 run_lib.py:145] step: 37950, training_loss: 1.51477e+02
I0506 13:09:55.100089 140299910223616 run_lib.py:145] step: 38000, training_loss: 1.58261e+02
I0506 13:09:55.149825 140299910223616 run_lib.py:158] step: 38000, eval_loss: 1.09694e+02
I0506 13:10:01.999855 140299910223616 run_lib.py:145] step: 38050, training_loss: 1.70869e+02
I0506 13:10:09.190291 140299910223616 run_lib.py:145] step: 38100, training_loss: 1.38205e+02
I0506 13:10:09.249240 140299910223616 run_lib.py:158] step: 38100, eval_loss: 1.93338e+02
I0506 13:10:16.017730 140299910223616 run_lib.py:145] step: 38150, training_loss: 1.52586e+02
I0506 13:10:22.789881 140299910223616 run_lib.py:145] step: 38200, training_loss: 1.47973e+02
I0506 13:10:22.849756 140299910223616 run_lib.py:158] step: 38200, eval_loss: 2.19501e+02
I0506 13:10:29.334587 140299910223616 run_lib.py:145] step: 38250, training_loss: 1.58951e+02
I0506 13:10:36.432820 140299910223616 run_lib.py:145] step: 38300, training_loss: 1.62349e+02
I0506 13:10:36.495422 140299910223616 run_lib.py:158] step: 38300, eval_loss: 2.11218e+02
I0506 13:10:43.234719 140299910223616 run_lib.py:145] step: 38350, training_loss: 1.48237e+02
I0506 13:10:50.044189 140299910223616 run_lib.py:145] step: 38400, training_loss: 1.44642e+02
I0506 13:10:50.103775 140299910223616 run_lib.py:158] step: 38400, eval_loss: 1.29118e+02
I0506 13:10:57.092178 140299910223616 run_lib.py:145] step: 38450, training_loss: 9.61840e+01
I0506 13:11:03.953459 140299910223616 run_lib.py:145] step: 38500, training_loss: 1.69567e+02
I0506 13:11:04.014074 140299910223616 run_lib.py:158] step: 38500, eval_loss: 1.49695e+02
I0506 13:11:10.586400 140299910223616 run_lib.py:145] step: 38550, training_loss: 1.36240e+02
I0506 13:11:17.400621 140299910223616 run_lib.py:145] step: 38600, training_loss: 1.07678e+02
I0506 13:11:17.450416 140299910223616 run_lib.py:158] step: 38600, eval_loss: 1.48378e+02
I0506 13:11:24.511247 140299910223616 run_lib.py:145] step: 38650, training_loss: 1.08408e+02
I0506 13:11:31.056476 140299910223616 run_lib.py:145] step: 38700, training_loss: 1.10379e+02
I0506 13:11:31.112014 140299910223616 run_lib.py:158] step: 38700, eval_loss: 1.56387e+02
I0506 13:11:37.978535 140299910223616 run_lib.py:145] step: 38750, training_loss: 9.57282e+01
I0506 13:11:44.835384 140299910223616 run_lib.py:145] step: 38800, training_loss: 1.99097e+02
I0506 13:11:44.892381 140299910223616 run_lib.py:158] step: 38800, eval_loss: 1.53399e+02
I0506 13:11:51.679045 140299910223616 run_lib.py:145] step: 38850, training_loss: 1.59013e+02
I0506 13:11:58.328731 140299910223616 run_lib.py:145] step: 38900, training_loss: 1.50175e+02
I0506 13:11:58.390096 140299910223616 run_lib.py:158] step: 38900, eval_loss: 1.43110e+02
I0506 13:12:05.277991 140299910223616 run_lib.py:145] step: 38950, training_loss: 1.62873e+02
I0506 13:12:12.109155 140299910223616 run_lib.py:145] step: 39000, training_loss: 1.61333e+02
I0506 13:12:12.178273 140299910223616 run_lib.py:158] step: 39000, eval_loss: 2.19466e+02
I0506 13:12:18.900145 140299910223616 run_lib.py:145] step: 39050, training_loss: 1.29655e+02
I0506 13:12:25.468772 140299910223616 run_lib.py:145] step: 39100, training_loss: 1.51088e+02
I0506 13:12:25.522472 140299910223616 run_lib.py:158] step: 39100, eval_loss: 1.54794e+02
I0506 13:12:32.545465 140299910223616 run_lib.py:145] step: 39150, training_loss: 1.27457e+02
I0506 13:12:39.179061 140299910223616 run_lib.py:145] step: 39200, training_loss: 9.00043e+01
I0506 13:12:39.231634 140299910223616 run_lib.py:158] step: 39200, eval_loss: 1.18539e+02
I0506 13:12:45.922909 140299910223616 run_lib.py:145] step: 39250, training_loss: 1.67889e+02
I0506 13:12:52.800601 140299910223616 run_lib.py:145] step: 39300, training_loss: 1.49002e+02
I0506 13:12:52.860130 140299910223616 run_lib.py:158] step: 39300, eval_loss: 1.87333e+02
I0506 13:12:59.863233 140299910223616 run_lib.py:145] step: 39350, training_loss: 1.46919e+02
I0506 13:13:06.577829 140299910223616 run_lib.py:145] step: 39400, training_loss: 1.08527e+02
I0506 13:13:06.636072 140299910223616 run_lib.py:158] step: 39400, eval_loss: 9.83909e+01
I0506 13:13:13.292612 140299910223616 run_lib.py:145] step: 39450, training_loss: 2.08523e+02
I0506 13:13:20.218347 140299910223616 run_lib.py:145] step: 39500, training_loss: 1.25233e+02
I0506 13:13:20.271269 140299910223616 run_lib.py:158] step: 39500, eval_loss: 1.90012e+02
I0506 13:13:26.959306 140299910223616 run_lib.py:145] step: 39550, training_loss: 9.02813e+01
I0506 13:13:33.739931 140299910223616 run_lib.py:145] step: 39600, training_loss: 1.81041e+02
I0506 13:13:33.797658 140299910223616 run_lib.py:158] step: 39600, eval_loss: 1.03514e+02
I0506 13:13:40.574592 140299910223616 run_lib.py:145] step: 39650, training_loss: 1.43669e+02
I0506 13:13:47.375553 140299910223616 run_lib.py:145] step: 39700, training_loss: 7.46669e+01
I0506 13:13:47.434941 140299910223616 run_lib.py:158] step: 39700, eval_loss: 1.66242e+02
I0506 13:13:54.257453 140299910223616 run_lib.py:145] step: 39750, training_loss: 1.49815e+02
I0506 13:14:00.800405 140299910223616 run_lib.py:145] step: 39800, training_loss: 1.49894e+02
I0506 13:14:00.859162 140299910223616 run_lib.py:158] step: 39800, eval_loss: 9.65616e+01
I0506 13:14:07.890057 140299910223616 run_lib.py:145] step: 39850, training_loss: 1.91426e+02
I0506 13:14:14.790867 140299910223616 run_lib.py:145] step: 39900, training_loss: 1.73169e+02
I0506 13:14:14.851482 140299910223616 run_lib.py:158] step: 39900, eval_loss: 1.78796e+02
I0506 13:14:21.564295 140299910223616 run_lib.py:145] step: 39950, training_loss: 1.04174e+02
I0506 13:14:28.415863 140299910223616 run_lib.py:145] step: 40000, training_loss: 1.59582e+02
I0506 13:14:28.644956 140299910223616 run_lib.py:158] step: 40000, eval_loss: 1.11200e+02
I0506 13:14:35.842490 140299910223616 run_lib.py:145] step: 40050, training_loss: 1.36162e+02
I0506 13:14:42.531574 140299910223616 run_lib.py:145] step: 40100, training_loss: 1.55822e+02
I0506 13:14:42.585631 140299910223616 run_lib.py:158] step: 40100, eval_loss: 1.11247e+02
I0506 13:14:49.393873 140299910223616 run_lib.py:145] step: 40150, training_loss: 1.03257e+02
I0506 13:14:56.274987 140299910223616 run_lib.py:145] step: 40200, training_loss: 1.70801e+02
I0506 13:14:56.330641 140299910223616 run_lib.py:158] step: 40200, eval_loss: 1.51950e+02
I0506 13:15:03.168759 140299910223616 run_lib.py:145] step: 40250, training_loss: 9.13430e+01
I0506 13:15:09.817600 140299910223616 run_lib.py:145] step: 40300, training_loss: 2.02443e+02
I0506 13:15:09.880102 140299910223616 run_lib.py:158] step: 40300, eval_loss: 8.55348e+01
I0506 13:15:16.784908 140299910223616 run_lib.py:145] step: 40350, training_loss: 1.34785e+02
I0506 13:15:23.787510 140299910223616 run_lib.py:145] step: 40400, training_loss: 1.39052e+02
I0506 13:15:23.838464 140299910223616 run_lib.py:158] step: 40400, eval_loss: 1.84398e+02
I0506 13:15:30.602251 140299910223616 run_lib.py:145] step: 40450, training_loss: 1.68289e+02
I0506 13:15:37.516078 140299910223616 run_lib.py:145] step: 40500, training_loss: 1.31268e+02
I0506 13:15:37.570632 140299910223616 run_lib.py:158] step: 40500, eval_loss: 1.51136e+02
I0506 13:15:44.544084 140299910223616 run_lib.py:145] step: 40550, training_loss: 1.49682e+02
I0506 13:15:51.192871 140299910223616 run_lib.py:145] step: 40600, training_loss: 1.47420e+02
I0506 13:15:51.255545 140299910223616 run_lib.py:158] step: 40600, eval_loss: 1.36633e+02
I0506 13:15:57.944565 140299910223616 run_lib.py:145] step: 40650, training_loss: 1.09124e+02
I0506 13:16:05.078037 140299910223616 run_lib.py:145] step: 40700, training_loss: 1.92896e+02
I0506 13:16:05.137013 140299910223616 run_lib.py:158] step: 40700, eval_loss: 1.37233e+02
I0506 13:16:11.817422 140299910223616 run_lib.py:145] step: 40750, training_loss: 1.96179e+02
I0506 13:16:18.519834 140299910223616 run_lib.py:145] step: 40800, training_loss: 8.97468e+01
I0506 13:16:18.584284 140299910223616 run_lib.py:158] step: 40800, eval_loss: 1.25039e+02
I0506 13:16:25.503020 140299910223616 run_lib.py:145] step: 40850, training_loss: 1.74602e+02
I0506 13:16:32.365322 140299910223616 run_lib.py:145] step: 40900, training_loss: 1.35604e+02
I0506 13:16:32.426336 140299910223616 run_lib.py:158] step: 40900, eval_loss: 7.32827e+01
I0506 13:16:39.106871 140299910223616 run_lib.py:145] step: 40950, training_loss: 1.76403e+02
I0506 13:16:45.815088 140299910223616 run_lib.py:145] step: 41000, training_loss: 1.05353e+02
I0506 13:16:45.867979 140299910223616 run_lib.py:158] step: 41000, eval_loss: 1.88250e+02
I0506 13:16:52.788049 140299910223616 run_lib.py:145] step: 41050, training_loss: 2.25074e+02
I0506 13:16:59.395452 140299910223616 run_lib.py:145] step: 41100, training_loss: 1.11313e+02
I0506 13:16:59.450506 140299910223616 run_lib.py:158] step: 41100, eval_loss: 9.62261e+01
I0506 13:17:06.175506 140299910223616 run_lib.py:145] step: 41150, training_loss: 1.62496e+02
I0506 13:17:12.810975 140299910223616 run_lib.py:145] step: 41200, training_loss: 1.38309e+02
I0506 13:17:12.867338 140299910223616 run_lib.py:158] step: 41200, eval_loss: 9.17166e+01
I0506 13:17:19.897130 140299910223616 run_lib.py:145] step: 41250, training_loss: 1.75456e+02
I0506 13:17:26.719915 140299910223616 run_lib.py:145] step: 41300, training_loss: 2.07410e+02
I0506 13:17:26.769795 140299910223616 run_lib.py:158] step: 41300, eval_loss: 1.53052e+02
I0506 13:17:33.715574 140299910223616 run_lib.py:145] step: 41350, training_loss: 1.27770e+02
I0506 13:17:40.852928 140299910223616 run_lib.py:145] step: 41400, training_loss: 1.01171e+02
I0506 13:17:40.905139 140299910223616 run_lib.py:158] step: 41400, eval_loss: 2.01529e+02
I0506 13:17:47.642382 140299910223616 run_lib.py:145] step: 41450, training_loss: 7.84365e+01
I0506 13:17:54.600227 140299910223616 run_lib.py:145] step: 41500, training_loss: 1.20141e+02
I0506 13:17:54.655565 140299910223616 run_lib.py:158] step: 41500, eval_loss: 1.46219e+02
I0506 13:18:01.146160 140299910223616 run_lib.py:145] step: 41550, training_loss: 1.02665e+02
I0506 13:18:08.225172 140299910223616 run_lib.py:145] step: 41600, training_loss: 1.37702e+02
I0506 13:18:08.279983 140299910223616 run_lib.py:158] step: 41600, eval_loss: 1.16909e+02
I0506 13:18:14.970836 140299910223616 run_lib.py:145] step: 41650, training_loss: 2.32243e+02
I0506 13:18:21.717115 140299910223616 run_lib.py:145] step: 41700, training_loss: 2.01747e+02
I0506 13:18:21.775370 140299910223616 run_lib.py:158] step: 41700, eval_loss: 8.15307e+01
I0506 13:18:28.668240 140299910223616 run_lib.py:145] step: 41750, training_loss: 1.14194e+02
I0506 13:18:35.512773 140299910223616 run_lib.py:145] step: 41800, training_loss: 2.36062e+02
I0506 13:18:35.577875 140299910223616 run_lib.py:158] step: 41800, eval_loss: 1.12125e+02
I0506 13:18:42.324643 140299910223616 run_lib.py:145] step: 41850, training_loss: 1.65689e+02
I0506 13:18:48.952446 140299910223616 run_lib.py:145] step: 41900, training_loss: 1.90462e+02
I0506 13:18:49.009248 140299910223616 run_lib.py:158] step: 41900, eval_loss: 2.39594e+02
I0506 13:18:56.053538 140299910223616 run_lib.py:145] step: 41950, training_loss: 1.43598e+02
I0506 13:19:02.800880 140299910223616 run_lib.py:145] step: 42000, training_loss: 1.68408e+02
I0506 13:19:02.856206 140299910223616 run_lib.py:158] step: 42000, eval_loss: 1.81880e+02
I0506 13:19:09.620793 140299910223616 run_lib.py:145] step: 42050, training_loss: 2.28910e+02
I0506 13:19:16.795158 140299910223616 run_lib.py:145] step: 42100, training_loss: 1.31885e+02
I0506 13:19:16.849102 140299910223616 run_lib.py:158] step: 42100, eval_loss: 2.01978e+02
I0506 13:19:23.576634 140299910223616 run_lib.py:145] step: 42150, training_loss: 1.44688e+02
I0506 13:19:30.294520 140299910223616 run_lib.py:145] step: 42200, training_loss: 2.31179e+02
I0506 13:19:30.355458 140299910223616 run_lib.py:158] step: 42200, eval_loss: 1.15617e+02
I0506 13:19:37.029804 140299910223616 run_lib.py:145] step: 42250, training_loss: 2.18160e+02
I0506 13:19:44.222904 140299910223616 run_lib.py:145] step: 42300, training_loss: 2.02823e+02
I0506 13:19:44.279119 140299910223616 run_lib.py:158] step: 42300, eval_loss: 1.53666e+02
I0506 13:19:51.189083 140299910223616 run_lib.py:145] step: 42350, training_loss: 7.40473e+01
I0506 13:19:57.869233 140299910223616 run_lib.py:145] step: 42400, training_loss: 1.52406e+02
I0506 13:19:57.926017 140299910223616 run_lib.py:158] step: 42400, eval_loss: 1.40552e+02
I0506 13:20:05.071004 140299910223616 run_lib.py:145] step: 42450, training_loss: 1.50920e+02
I0506 13:20:11.932093 140299910223616 run_lib.py:145] step: 42500, training_loss: 2.00367e+02
I0506 13:20:11.985616 140299910223616 run_lib.py:158] step: 42500, eval_loss: 1.19485e+02
I0506 13:20:18.753882 140299910223616 run_lib.py:145] step: 42550, training_loss: 1.99423e+02
I0506 13:20:25.735236 140299910223616 run_lib.py:145] step: 42600, training_loss: 1.02582e+02
I0506 13:20:25.790860 140299910223616 run_lib.py:158] step: 42600, eval_loss: 2.10449e+02
I0506 13:20:32.869254 140299910223616 run_lib.py:145] step: 42650, training_loss: 1.37230e+02
I0506 13:20:39.507245 140299910223616 run_lib.py:145] step: 42700, training_loss: 1.66436e+02
I0506 13:20:39.567868 140299910223616 run_lib.py:158] step: 42700, eval_loss: 1.59520e+02
I0506 13:20:46.363205 140299910223616 run_lib.py:145] step: 42750, training_loss: 1.23374e+02
I0506 13:20:53.494464 140299910223616 run_lib.py:145] step: 42800, training_loss: 1.91669e+02
I0506 13:20:53.550203 140299910223616 run_lib.py:158] step: 42800, eval_loss: 2.05756e+02
I0506 13:21:00.084954 140299910223616 run_lib.py:145] step: 42850, training_loss: 1.96068e+02
I0506 13:21:06.893508 140299910223616 run_lib.py:145] step: 42900, training_loss: 1.62188e+02
I0506 13:21:06.948375 140299910223616 run_lib.py:158] step: 42900, eval_loss: 1.78406e+02
I0506 13:21:13.718291 140299910223616 run_lib.py:145] step: 42950, training_loss: 2.03954e+02
I0506 13:21:20.697435 140299910223616 run_lib.py:145] step: 43000, training_loss: 1.37569e+02
I0506 13:21:20.751431 140299910223616 run_lib.py:158] step: 43000, eval_loss: 1.84065e+02
I0506 13:21:27.549040 140299910223616 run_lib.py:145] step: 43050, training_loss: 2.49987e+02
I0506 13:21:34.176801 140299910223616 run_lib.py:145] step: 43100, training_loss: 1.71266e+02
I0506 13:21:34.230792 140299910223616 run_lib.py:158] step: 43100, eval_loss: 1.13459e+02
I0506 13:21:41.282430 140299910223616 run_lib.py:145] step: 43150, training_loss: 1.15097e+02
I0506 13:21:48.202440 140299910223616 run_lib.py:145] step: 43200, training_loss: 1.07985e+02
I0506 13:21:48.259737 140299910223616 run_lib.py:158] step: 43200, eval_loss: 1.65380e+02
I0506 13:21:54.981876 140299910223616 run_lib.py:145] step: 43250, training_loss: 6.79822e+01
I0506 13:22:01.693884 140299910223616 run_lib.py:145] step: 43300, training_loss: 2.07999e+02
I0506 13:22:01.746881 140299910223616 run_lib.py:158] step: 43300, eval_loss: 1.40615e+02
I0506 13:22:08.755827 140299910223616 run_lib.py:145] step: 43350, training_loss: 1.23450e+02
I0506 13:22:15.649926 140299910223616 run_lib.py:145] step: 43400, training_loss: 1.90562e+02
I0506 13:22:15.704202 140299910223616 run_lib.py:158] step: 43400, eval_loss: 1.03136e+02
I0506 13:22:22.420711 140299910223616 run_lib.py:145] step: 43450, training_loss: 2.24570e+02
I0506 13:22:29.340786 140299910223616 run_lib.py:145] step: 43500, training_loss: 1.50167e+02
I0506 13:22:29.396924 140299910223616 run_lib.py:158] step: 43500, eval_loss: 1.04777e+02
I0506 13:22:36.337357 140299910223616 run_lib.py:145] step: 43550, training_loss: 1.05899e+02
I0506 13:22:43.007001 140299910223616 run_lib.py:145] step: 43600, training_loss: 1.94494e+02
I0506 13:22:43.060306 140299910223616 run_lib.py:158] step: 43600, eval_loss: 1.61270e+02
I0506 13:22:49.667203 140299910223616 run_lib.py:145] step: 43650, training_loss: 1.94226e+02
I0506 13:22:56.593357 140299910223616 run_lib.py:145] step: 43700, training_loss: 1.46519e+02
I0506 13:22:56.647488 140299910223616 run_lib.py:158] step: 43700, eval_loss: 1.13889e+02
I0506 13:23:03.458329 140299910223616 run_lib.py:145] step: 43750, training_loss: 1.47258e+02
I0506 13:23:10.240687 140299910223616 run_lib.py:145] step: 43800, training_loss: 1.14570e+02
I0506 13:23:10.301889 140299910223616 run_lib.py:158] step: 43800, eval_loss: 1.53456e+02
I0506 13:23:17.300986 140299910223616 run_lib.py:145] step: 43850, training_loss: 1.94749e+02
I0506 13:23:24.171187 140299910223616 run_lib.py:145] step: 43900, training_loss: 2.23167e+02
I0506 13:23:24.225779 140299910223616 run_lib.py:158] step: 43900, eval_loss: 6.52466e+01
I0506 13:23:31.061914 140299910223616 run_lib.py:145] step: 43950, training_loss: 1.23624e+02
I0506 13:23:37.634050 140299910223616 run_lib.py:145] step: 44000, training_loss: 1.31271e+02
I0506 13:23:37.690375 140299910223616 run_lib.py:158] step: 44000, eval_loss: 1.50932e+02
I0506 13:23:44.743033 140299910223616 run_lib.py:145] step: 44050, training_loss: 1.31737e+02
I0506 13:23:51.355483 140299910223616 run_lib.py:145] step: 44100, training_loss: 1.81210e+02
I0506 13:23:51.414463 140299910223616 run_lib.py:158] step: 44100, eval_loss: 1.09072e+02
I0506 13:23:58.237533 140299910223616 run_lib.py:145] step: 44150, training_loss: 1.34975e+02
I0506 13:24:05.318746 140299910223616 run_lib.py:145] step: 44200, training_loss: 1.58889e+02
I0506 13:24:05.375743 140299910223616 run_lib.py:158] step: 44200, eval_loss: 1.58909e+02
I0506 13:24:12.054566 140299910223616 run_lib.py:145] step: 44250, training_loss: 2.01431e+02
I0506 13:24:18.727333 140299910223616 run_lib.py:145] step: 44300, training_loss: 1.84752e+02
I0506 13:24:18.786546 140299910223616 run_lib.py:158] step: 44300, eval_loss: 9.40474e+01
I0506 13:24:25.558421 140299910223616 run_lib.py:145] step: 44350, training_loss: 1.70824e+02
I0506 13:24:32.465383 140299910223616 run_lib.py:145] step: 44400, training_loss: 1.03610e+02
I0506 13:24:32.522578 140299910223616 run_lib.py:158] step: 44400, eval_loss: 9.66539e+01
I0506 13:24:39.425239 140299910223616 run_lib.py:145] step: 44450, training_loss: 1.62046e+02
I0506 13:24:46.089938 140299910223616 run_lib.py:145] step: 44500, training_loss: 1.50631e+02
I0506 13:24:46.146013 140299910223616 run_lib.py:158] step: 44500, eval_loss: 1.69004e+02
I0506 13:24:52.965035 140299910223616 run_lib.py:145] step: 44550, training_loss: 1.56978e+02
I0506 13:24:59.694254 140299910223616 run_lib.py:145] step: 44600, training_loss: 1.52574e+02
I0506 13:24:59.751696 140299910223616 run_lib.py:158] step: 44600, eval_loss: 1.47898e+02
I0506 13:25:06.735708 140299910223616 run_lib.py:145] step: 44650, training_loss: 1.53898e+02
I0506 13:25:13.333252 140299910223616 run_lib.py:145] step: 44700, training_loss: 2.27327e+02
I0506 13:25:13.389593 140299910223616 run_lib.py:158] step: 44700, eval_loss: 1.12887e+02
I0506 13:25:20.469980 140299910223616 run_lib.py:145] step: 44750, training_loss: 1.10011e+02
I0506 13:25:27.161993 140299910223616 run_lib.py:145] step: 44800, training_loss: 1.30311e+02
I0506 13:25:27.214769 140299910223616 run_lib.py:158] step: 44800, eval_loss: 1.52865e+02
I0506 13:25:34.079066 140299910223616 run_lib.py:145] step: 44850, training_loss: 1.15409e+02
I0506 13:25:41.174408 140299910223616 run_lib.py:145] step: 44900, training_loss: 7.47251e+01
I0506 13:25:41.233390 140299910223616 run_lib.py:158] step: 44900, eval_loss: 1.48633e+02
I0506 13:25:47.951508 140299910223616 run_lib.py:145] step: 44950, training_loss: 2.10204e+02
I0506 13:25:54.736294 140299910223616 run_lib.py:145] step: 45000, training_loss: 1.06728e+02
I0506 13:25:54.793346 140299910223616 run_lib.py:158] step: 45000, eval_loss: 1.00733e+02
I0506 13:26:01.584249 140299910223616 run_lib.py:145] step: 45050, training_loss: 1.60120e+02
I0506 13:26:08.453819 140299910223616 run_lib.py:145] step: 45100, training_loss: 1.45663e+02
I0506 13:26:08.509694 140299910223616 run_lib.py:158] step: 45100, eval_loss: 1.11666e+02
I0506 13:26:15.475304 140299910223616 run_lib.py:145] step: 45150, training_loss: 1.50951e+02
I0506 13:26:22.084550 140299910223616 run_lib.py:145] step: 45200, training_loss: 1.49928e+02
I0506 13:26:22.138357 140299910223616 run_lib.py:158] step: 45200, eval_loss: 1.66217e+02
I0506 13:26:29.228106 140299910223616 run_lib.py:145] step: 45250, training_loss: 2.00730e+02
I0506 13:26:35.861607 140299910223616 run_lib.py:145] step: 45300, training_loss: 1.65456e+02
I0506 13:26:35.915677 140299910223616 run_lib.py:158] step: 45300, eval_loss: 1.01278e+02
I0506 13:26:42.721827 140299910223616 run_lib.py:145] step: 45350, training_loss: 2.17670e+02
I0506 13:26:49.527611 140299910223616 run_lib.py:145] step: 45400, training_loss: 1.60133e+02
I0506 13:26:49.583449 140299910223616 run_lib.py:158] step: 45400, eval_loss: 2.25341e+02
I0506 13:26:56.413050 140299910223616 run_lib.py:145] step: 45450, training_loss: 1.33840e+02
I0506 13:27:03.042022 140299910223616 run_lib.py:145] step: 45500, training_loss: 1.94871e+02
I0506 13:27:03.103733 140299910223616 run_lib.py:158] step: 45500, eval_loss: 7.55688e+01
I0506 13:27:09.993935 140299910223616 run_lib.py:145] step: 45550, training_loss: 2.31022e+02
I0506 13:27:17.055847 140299910223616 run_lib.py:145] step: 45600, training_loss: 1.52201e+02
I0506 13:27:17.114032 140299910223616 run_lib.py:158] step: 45600, eval_loss: 1.50516e+02
I0506 13:27:23.649939 140299910223616 run_lib.py:145] step: 45650, training_loss: 1.15497e+02
I0506 13:27:30.226689 140299910223616 run_lib.py:145] step: 45700, training_loss: 1.41861e+02
I0506 13:27:30.281810 140299910223616 run_lib.py:158] step: 45700, eval_loss: 1.30104e+02
I0506 13:27:37.304647 140299910223616 run_lib.py:145] step: 45750, training_loss: 1.91248e+02
I0506 13:27:43.988198 140299910223616 run_lib.py:145] step: 45800, training_loss: 1.11694e+02
I0506 13:27:44.048456 140299910223616 run_lib.py:158] step: 45800, eval_loss: 9.44964e+01
I0506 13:27:50.779095 140299910223616 run_lib.py:145] step: 45850, training_loss: 7.77062e+01
I0506 13:27:57.252214 140299910223616 run_lib.py:145] step: 45900, training_loss: 1.18302e+02
I0506 13:27:57.306771 140299910223616 run_lib.py:158] step: 45900, eval_loss: 2.20603e+02
I0506 13:28:04.359196 140299910223616 run_lib.py:145] step: 45950, training_loss: 1.64264e+02
I0506 13:28:11.031161 140299910223616 run_lib.py:145] step: 46000, training_loss: 1.02554e+02
I0506 13:28:11.091247 140299910223616 run_lib.py:158] step: 46000, eval_loss: 7.42461e+01
I0506 13:28:17.992965 140299910223616 run_lib.py:145] step: 46050, training_loss: 1.84072e+02
I0506 13:28:24.778505 140299910223616 run_lib.py:145] step: 46100, training_loss: 1.48538e+02
I0506 13:28:24.835564 140299910223616 run_lib.py:158] step: 46100, eval_loss: 1.71164e+02
I0506 13:28:31.676716 140299910223616 run_lib.py:145] step: 46150, training_loss: 1.07932e+02
I0506 13:28:38.433481 140299910223616 run_lib.py:145] step: 46200, training_loss: 1.35454e+02
I0506 13:28:38.490097 140299910223616 run_lib.py:158] step: 46200, eval_loss: 1.95241e+02
I0506 13:28:45.251470 140299910223616 run_lib.py:145] step: 46250, training_loss: 1.54764e+02
I0506 13:28:52.141351 140299910223616 run_lib.py:145] step: 46300, training_loss: 1.40585e+02
I0506 13:28:52.198545 140299910223616 run_lib.py:158] step: 46300, eval_loss: 1.52610e+02
I0506 13:28:58.918227 140299910223616 run_lib.py:145] step: 46350, training_loss: 1.99750e+02
I0506 13:29:05.660005 140299910223616 run_lib.py:145] step: 46400, training_loss: 1.56942e+02
I0506 13:29:05.711078 140299910223616 run_lib.py:158] step: 46400, eval_loss: 1.52064e+02
I0506 13:29:12.726560 140299910223616 run_lib.py:145] step: 46450, training_loss: 1.64011e+02
I0506 13:29:19.422493 140299910223616 run_lib.py:145] step: 46500, training_loss: 1.19503e+02
I0506 13:29:19.480367 140299910223616 run_lib.py:158] step: 46500, eval_loss: 1.39112e+02
I0506 13:29:26.320893 140299910223616 run_lib.py:145] step: 46550, training_loss: 1.11928e+02
I0506 13:29:32.940582 140299910223616 run_lib.py:145] step: 46600, training_loss: 1.22588e+02
I0506 13:29:32.989275 140299910223616 run_lib.py:158] step: 46600, eval_loss: 7.16905e+01
I0506 13:29:39.868801 140299910223616 run_lib.py:145] step: 46650, training_loss: 1.88566e+02
I0506 13:29:46.470358 140299910223616 run_lib.py:145] step: 46700, training_loss: 9.36198e+01
I0506 13:29:46.530546 140299910223616 run_lib.py:158] step: 46700, eval_loss: 1.20299e+02
I0506 13:29:53.459740 140299910223616 run_lib.py:145] step: 46750, training_loss: 1.28013e+02
I0506 13:30:00.316330 140299910223616 run_lib.py:145] step: 46800, training_loss: 1.56919e+02
I0506 13:30:00.368258 140299910223616 run_lib.py:158] step: 46800, eval_loss: 1.21217e+02
I0506 13:30:07.373722 140299910223616 run_lib.py:145] step: 46850, training_loss: 1.26447e+02
I0506 13:30:13.967178 140299910223616 run_lib.py:145] step: 46900, training_loss: 1.32075e+02
I0506 13:30:14.018697 140299910223616 run_lib.py:158] step: 46900, eval_loss: 1.35367e+02
I0506 13:30:20.632415 140299910223616 run_lib.py:145] step: 46950, training_loss: 1.09320e+02
I0506 13:30:27.849681 140299910223616 run_lib.py:145] step: 47000, training_loss: 1.52299e+02
I0506 13:30:27.902809 140299910223616 run_lib.py:158] step: 47000, eval_loss: 1.44438e+02
I0506 13:30:34.808161 140299910223616 run_lib.py:145] step: 47050, training_loss: 1.59333e+02
I0506 13:30:41.715915 140299910223616 run_lib.py:145] step: 47100, training_loss: 1.73567e+02
I0506 13:30:41.770199 140299910223616 run_lib.py:158] step: 47100, eval_loss: 1.28680e+02
I0506 13:30:48.840249 140299910223616 run_lib.py:145] step: 47150, training_loss: 1.29487e+02
I0506 13:30:55.541458 140299910223616 run_lib.py:145] step: 47200, training_loss: 1.53389e+02
I0506 13:30:55.602557 140299910223616 run_lib.py:158] step: 47200, eval_loss: 2.16204e+02
I0506 13:31:02.293491 140299910223616 run_lib.py:145] step: 47250, training_loss: 1.40573e+02
I0506 13:31:08.985256 140299910223616 run_lib.py:145] step: 47300, training_loss: 1.44542e+02
I0506 13:31:09.043114 140299910223616 run_lib.py:158] step: 47300, eval_loss: 1.07093e+02
I0506 13:31:16.089598 140299910223616 run_lib.py:145] step: 47350, training_loss: 1.13549e+02
I0506 13:31:22.838776 140299910223616 run_lib.py:145] step: 47400, training_loss: 1.56240e+02
I0506 13:31:22.895798 140299910223616 run_lib.py:158] step: 47400, eval_loss: 2.40310e+02
I0506 13:31:29.492573 140299910223616 run_lib.py:145] step: 47450, training_loss: 1.20307e+02
I0506 13:31:36.558785 140299910223616 run_lib.py:145] step: 47500, training_loss: 1.17197e+02
I0506 13:31:36.615435 140299910223616 run_lib.py:158] step: 47500, eval_loss: 1.16103e+02
I0506 13:31:43.238228 140299910223616 run_lib.py:145] step: 47550, training_loss: 8.16591e+01
I0506 13:31:49.879896 140299910223616 run_lib.py:145] step: 47600, training_loss: 1.67905e+02
I0506 13:31:49.939269 140299910223616 run_lib.py:158] step: 47600, eval_loss: 1.39777e+02
I0506 13:31:56.817409 140299910223616 run_lib.py:145] step: 47650, training_loss: 8.68566e+01
I0506 13:32:03.647462 140299910223616 run_lib.py:145] step: 47700, training_loss: 1.06476e+02
I0506 13:32:03.700324 140299910223616 run_lib.py:158] step: 47700, eval_loss: 1.36986e+02
I0506 13:32:10.584364 140299910223616 run_lib.py:145] step: 47750, training_loss: 1.10746e+02
I0506 13:32:17.306215 140299910223616 run_lib.py:145] step: 47800, training_loss: 1.44535e+02
I0506 13:32:17.361314 140299910223616 run_lib.py:158] step: 47800, eval_loss: 1.54327e+02
I0506 13:32:24.424288 140299910223616 run_lib.py:145] step: 47850, training_loss: 1.34078e+02
I0506 13:32:31.188833 140299910223616 run_lib.py:145] step: 47900, training_loss: 1.75436e+02
I0506 13:32:31.245596 140299910223616 run_lib.py:158] step: 47900, eval_loss: 1.43401e+02
I0506 13:32:38.141063 140299910223616 run_lib.py:145] step: 47950, training_loss: 1.51966e+02
I0506 13:32:44.910956 140299910223616 run_lib.py:145] step: 48000, training_loss: 1.29621e+02
I0506 13:32:44.969967 140299910223616 run_lib.py:158] step: 48000, eval_loss: 1.37650e+02
I0506 13:32:52.055665 140299910223616 run_lib.py:145] step: 48050, training_loss: 1.20312e+02
I0506 13:32:58.689286 140299910223616 run_lib.py:145] step: 48100, training_loss: 1.57721e+02
I0506 13:32:58.740762 140299910223616 run_lib.py:158] step: 48100, eval_loss: 1.59151e+02
I0506 13:33:05.451576 140299910223616 run_lib.py:145] step: 48150, training_loss: 1.55439e+02
I0506 13:33:12.247978 140299910223616 run_lib.py:145] step: 48200, training_loss: 2.01001e+02
I0506 13:33:12.305545 140299910223616 run_lib.py:158] step: 48200, eval_loss: 1.10781e+02
I0506 13:33:18.965502 140299910223616 run_lib.py:145] step: 48250, training_loss: 1.44830e+02
I0506 13:33:25.714583 140299910223616 run_lib.py:145] step: 48300, training_loss: 1.47333e+02
I0506 13:33:25.766256 140299910223616 run_lib.py:158] step: 48300, eval_loss: 7.90913e+01
I0506 13:33:32.391909 140299910223616 run_lib.py:145] step: 48350, training_loss: 1.42524e+02
I0506 13:33:39.217226 140299910223616 run_lib.py:145] step: 48400, training_loss: 2.22102e+02
I0506 13:33:39.275681 140299910223616 run_lib.py:158] step: 48400, eval_loss: 1.18397e+02
I0506 13:33:46.197673 140299910223616 run_lib.py:145] step: 48450, training_loss: 1.40889e+02
I0506 13:33:52.825881 140299910223616 run_lib.py:145] step: 48500, training_loss: 1.51265e+02
I0506 13:33:52.882654 140299910223616 run_lib.py:158] step: 48500, eval_loss: 1.50689e+02
I0506 13:33:59.801923 140299910223616 run_lib.py:145] step: 48550, training_loss: 1.43321e+02
I0506 13:34:06.544072 140299910223616 run_lib.py:145] step: 48600, training_loss: 1.02050e+02
I0506 13:34:06.602144 140299910223616 run_lib.py:158] step: 48600, eval_loss: 1.22523e+02
I0506 13:34:13.282524 140299910223616 run_lib.py:145] step: 48650, training_loss: 1.82137e+02
I0506 13:34:20.206297 140299910223616 run_lib.py:145] step: 48700, training_loss: 1.33187e+02
I0506 13:34:20.267696 140299910223616 run_lib.py:158] step: 48700, eval_loss: 9.10281e+01
I0506 13:34:27.184653 140299910223616 run_lib.py:145] step: 48750, training_loss: 9.07971e+01
I0506 13:34:34.020107 140299910223616 run_lib.py:145] step: 48800, training_loss: 1.46405e+02
I0506 13:34:34.074525 140299910223616 run_lib.py:158] step: 48800, eval_loss: 7.55650e+01
I0506 13:34:40.735986 140299910223616 run_lib.py:145] step: 48850, training_loss: 1.73842e+02
I0506 13:34:47.585217 140299910223616 run_lib.py:145] step: 48900, training_loss: 1.14425e+02
I0506 13:34:47.642663 140299910223616 run_lib.py:158] step: 48900, eval_loss: 9.47324e+01
I0506 13:34:54.178855 140299910223616 run_lib.py:145] step: 48950, training_loss: 1.34757e+02
I0506 13:35:01.013199 140299910223616 run_lib.py:145] step: 49000, training_loss: 2.04563e+02
I0506 13:35:01.070189 140299910223616 run_lib.py:158] step: 49000, eval_loss: 1.75775e+02
I0506 13:35:07.771413 140299910223616 run_lib.py:145] step: 49050, training_loss: 1.17466e+02
I0506 13:35:14.837065 140299910223616 run_lib.py:145] step: 49100, training_loss: 2.24481e+02
I0506 13:35:14.892152 140299910223616 run_lib.py:158] step: 49100, eval_loss: 1.31181e+02
I0506 13:35:21.682504 140299910223616 run_lib.py:145] step: 49150, training_loss: 1.73096e+02
I0506 13:35:28.378107 140299910223616 run_lib.py:145] step: 49200, training_loss: 1.77172e+02
I0506 13:35:28.438709 140299910223616 run_lib.py:158] step: 49200, eval_loss: 1.67515e+02
I0506 13:35:35.524343 140299910223616 run_lib.py:145] step: 49250, training_loss: 1.32447e+02
I0506 13:35:41.999495 140299910223616 run_lib.py:145] step: 49300, training_loss: 1.74620e+02
I0506 13:35:42.059489 140299910223616 run_lib.py:158] step: 49300, eval_loss: 1.59909e+02
I0506 13:35:48.822147 140299910223616 run_lib.py:145] step: 49350, training_loss: 1.35749e+02
I0506 13:35:55.622325 140299910223616 run_lib.py:145] step: 49400, training_loss: 8.76815e+01
I0506 13:35:55.681352 140299910223616 run_lib.py:158] step: 49400, eval_loss: 1.44427e+02
I0506 13:36:02.532625 140299910223616 run_lib.py:145] step: 49450, training_loss: 2.23919e+02
I0506 13:36:09.355844 140299910223616 run_lib.py:145] step: 49500, training_loss: 9.73623e+01
I0506 13:36:09.415973 140299910223616 run_lib.py:158] step: 49500, eval_loss: 1.30614e+02
I0506 13:36:16.063428 140299910223616 run_lib.py:145] step: 49550, training_loss: 1.79586e+02
I0506 13:36:22.922962 140299910223616 run_lib.py:145] step: 49600, training_loss: 1.92718e+02
I0506 13:36:22.978447 140299910223616 run_lib.py:158] step: 49600, eval_loss: 1.16953e+02
I0506 13:36:29.692543 140299910223616 run_lib.py:145] step: 49650, training_loss: 1.22034e+02
I0506 13:36:36.296003 140299910223616 run_lib.py:145] step: 49700, training_loss: 8.15805e+01
I0506 13:36:36.346300 140299910223616 run_lib.py:158] step: 49700, eval_loss: 1.65074e+02
I0506 13:36:42.962112 140299910223616 run_lib.py:145] step: 49750, training_loss: 1.16788e+02
I0506 13:36:49.968561 140299910223616 run_lib.py:145] step: 49800, training_loss: 8.53339e+01
I0506 13:36:50.027974 140299910223616 run_lib.py:158] step: 49800, eval_loss: 6.15370e+01
I0506 13:36:56.878200 140299910223616 run_lib.py:145] step: 49850, training_loss: 1.97934e+02
I0506 13:37:03.513170 140299910223616 run_lib.py:145] step: 49900, training_loss: 1.25345e+02
I0506 13:37:03.570993 140299910223616 run_lib.py:158] step: 49900, eval_loss: 9.01342e+01
I0506 13:37:10.633426 140299910223616 run_lib.py:145] step: 49950, training_loss: 1.38750e+02
I0506 13:37:17.304154 140299910223616 run_lib.py:145] step: 50000, training_loss: 8.24576e+01
I0506 13:37:17.532141 140299910223616 run_lib.py:158] step: 50000, eval_loss: 1.43733e+02
Traceback (most recent call last):
  File "main.py", line 63, in <module>
    app.run(main)
  File "/vilsrv-storage/dinari/miniconda3/envs/condirit/lib/python3.8/site-packages/absl/app.py", line 312, in run
    _run_main(main, args)
  File "/vilsrv-storage/dinari/miniconda3/envs/condirit/lib/python3.8/site-packages/absl/app.py", line 258, in _run_main
    sys.exit(main(argv))
  File "main.py", line 54, in main
    run_lib.train(FLAGS.config, FLAGS.workdir)
  File "/vilsrv-storage/tohamy/BNP/SDE/score_sde_pytorch/run_lib.py", line 171, in train
    sample, n = sampling_fn(score_model)
  File "/vilsrv-storage/tohamy/BNP/SDE/score_sde_pytorch/sampling.py", line 407, in pc_sampler
    x, x_mean = predictor_update_fn(x, vec_t, model=model)
  File "/vilsrv-storage/tohamy/BNP/SDE/score_sde_pytorch/sampling.py", line 341, in shared_predictor_update_fn
    return predictor_obj.update_fn(x, t)
  File "/vilsrv-storage/tohamy/BNP/SDE/score_sde_pytorch/sampling.py", line 196, in update_fn
    f, G = self.rsde.discretize(x, t)
  File "/vilsrv-storage/tohamy/BNP/SDE/score_sde_pytorch/sde_lib.py", line 105, in discretize
    rev_f = f - G[:, None, None, None] ** 2 * score_fn(x, t) * (0.5 if self.probability_flow else 1.)
  File "/vilsrv-storage/tohamy/BNP/SDE/score_sde_pytorch/models/utils.py", line 173, in score_fn
    score = model_fn(x, labels)
  File "/vilsrv-storage/tohamy/BNP/SDE/score_sde_pytorch/models/utils.py", line 122, in model_fn
    return model(x, labels)
  File "/vilsrv-storage/dinari/miniconda3/envs/condirit/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/vilsrv-storage/dinari/miniconda3/envs/condirit/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/vilsrv-storage/dinari/miniconda3/envs/condirit/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/vilsrv-storage/dinari/miniconda3/envs/condirit/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/vilsrv-storage/dinari/miniconda3/envs/condirit/lib/python3.8/site-packages/torch/_utils.py", line 425, in reraise
    raise self.exc_type(msg)
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/vilsrv-storage/dinari/miniconda3/envs/condirit/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/vilsrv-storage/dinari/miniconda3/envs/condirit/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/vilsrv-storage/tohamy/BNP/SDE/score_sde_pytorch/models/ddpm.py", line 132, in forward
    hs = [modules[m_idx](h)]
  File "/vilsrv-storage/dinari/miniconda3/envs/condirit/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/vilsrv-storage/dinari/miniconda3/envs/condirit/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 443, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/vilsrv-storage/dinari/miniconda3/envs/condirit/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 439, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Input type (torch.cuda.DoubleTensor) and weight type (torch.cuda.FloatTensor) should be the same

